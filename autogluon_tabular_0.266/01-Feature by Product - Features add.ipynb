{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from functools import partial# import ace_tools as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directorios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS_DIR = '../../data/'\n",
    "SALIDAS_DIR = '../../salidas/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURA DE DATASET DE 16.6 MILLONES PARA TRANSFORMARLO POR PRODUCTO\n",
    "ESTE SCRIPT SE CORRE POR UNICA VEZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_SELL_IN='sell_in_fixed36.parquet'\n",
    "FILE_NAME_PRODUCTOS='tb_productos.txt'\n",
    "\n",
    "df = pd.read_parquet(DATOS_DIR + FILE_NAME_SELL_IN)\n",
    "df_productos = pd.read_csv(DATOS_DIR + FILE_NAME_PRODUCTOS , sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo el nuevo dataset agrupado por productos_id y periodos\n",
    "TOTAL DE PRODUCTO 780 X 36 PERIODOS PARA CADA UNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_id periodo_dt  cantidad_registros\n",
      "0        20001 2017-01-01                 186\n",
      "1        20001 2017-02-01                 185\n",
      "2        20001 2017-03-01                 188\n",
      "3        20001 2017-04-01                 104\n",
      "4        20001 2017-05-01                 238\n",
      "5        20001 2017-06-01                 220\n",
      "6        20001 2017-07-01                 151\n",
      "7        20001 2017-08-01                 236\n",
      "8        20001 2017-09-01                 163\n",
      "9        20001 2017-10-01                  96\n",
      "10       20001 2017-11-01                 175\n",
      "11       20001 2017-12-01                 192\n",
      "12       20001 2018-01-01                 152\n",
      "13       20001 2018-02-01                 157\n",
      "14       20001 2018-03-01                 204\n",
      "15       20001 2018-04-01                 154\n",
      "16       20001 2018-05-01                 188\n",
      "17       20001 2018-06-01                 188\n",
      "18       20001 2018-07-01                 167\n",
      "19       20001 2018-08-01                 193\n",
      "20       20001 2018-09-01                 171\n",
      "21       20001 2018-10-01                 158\n",
      "22       20001 2018-11-01                 175\n",
      "23       20001 2018-12-01                 182\n",
      "24       20001 2019-01-01                 142\n",
      "25       20001 2019-02-01                 165\n",
      "26       20001 2019-03-01                 191\n",
      "27       20001 2019-04-01                 177\n",
      "28       20001 2019-05-01                 122\n",
      "29       20001 2019-06-01                 182\n",
      "30       20001 2019-07-01                 181\n",
      "31       20001 2019-08-01                 163\n",
      "32       20001 2019-09-01                 166\n",
      "33       20001 2019-10-01                 128\n",
      "34       20001 2019-11-01                 156\n",
      "35       20001 2019-12-01                 176\n",
      "36       20002 2017-01-01                 152\n",
      "37       20002 2017-02-01                 162\n",
      "38       20002 2017-03-01                 188\n",
      "39       20002 2017-04-01                 163\n"
     ]
    }
   ],
   "source": [
    "# GUARDO EN UN DATASET # LOS REGISTROS QUE TENGAN TN > 0, AGRUPADOS POR product_id, customer_id Y periodo_dt\n",
    "\n",
    "# Filtrar registros donde tn > 0\n",
    "df_filtrado = df[df['tn'] > 0]\n",
    "\n",
    "# Agrupar por product_id, customer_id y periodo_dt, y contar los registros\n",
    "df_Customer_Compraron = df_filtrado.groupby(['product_id', 'periodo_dt'], as_index=False).size()\n",
    "\n",
    "# Renombrar la columna de conteo\n",
    "df_Customer_Compraron.rename(columns={'size': 'cantidad_registros'}, inplace=True)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_Customer_Compraron.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borro columnas que no voy a usar\n",
    "columnas_a_borrar = [\"customer_id\",\"is_synth\", \"is_synth_36\"]\n",
    "df.drop(columns=columnas_a_borrar, inplace=True, errors='ignore')\n",
    "# Agrupar por product_id y periodo_dt, y sumar el resto de los campos\n",
    "df_agrupado = df.groupby(['product_id', 'periodo_dt'], as_index=False).sum()\n",
    "df_exportar = pd.merge(df_agrupado, df_productos, on='product_id', how='left')\n",
    "\n",
    "# Exportar el DataFrame a un archivo Parquet\n",
    "\n",
    "FILE_NAME_SOLO_PRODUCTOS ='sell_in_ByProductos.parquet'\n",
    "df_exportar.to_parquet(DATOS_DIR + FILE_NAME_SOLO_PRODUCTOS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMIENZO FE CON DATASET POR PRODUCTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lECTURA DEL ARCHIVO PARQUET\n",
    "FILE_NAME_SOLO_PRODUCTOS ='sell_in_ByProductos.parquet'\n",
    "df = pd.read_parquet(DATOS_DIR + FILE_NAME_SOLO_PRODUCTOS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28080 entries, 0 to 28079\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   product_id             28080 non-null  int32         \n",
      " 1   periodo_dt             28080 non-null  datetime64[ns]\n",
      " 2   plan_precios_cuidados  28080 non-null  int64         \n",
      " 3   cust_request_qty       28080 non-null  float64       \n",
      " 4   cust_request_tn        28080 non-null  float32       \n",
      " 5   tn                     28080 non-null  float32       \n",
      " 6   cat1                   28080 non-null  object        \n",
      " 7   cat2                   28080 non-null  object        \n",
      " 8   cat3                   28080 non-null  object        \n",
      " 9   brand                  28080 non-null  object        \n",
      " 10  sku_size               28080 non-null  int64         \n",
      " 11  descripcion            28080 non-null  object        \n",
      "dtypes: datetime64[ns](1), float32(2), float64(1), int32(1), int64(2), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupo por product_id, customer_id y periodo_dt, y cuento los registros cuando la suma de tn >0\n",
    "df_agrupado = df.groupby(['product_id', 'customer_id', 'periodo_dt'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego periodo de 0 a 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo_mapping = {\n",
    "    pd.to_datetime(\"2017-01-01\"): 0, pd.to_datetime(\"2017-02-01\"): 1, pd.to_datetime(\"2017-03-01\"): 2,\n",
    "    pd.to_datetime(\"2017-04-01\"): 3, pd.to_datetime(\"2017-05-01\"): 4, pd.to_datetime(\"2017-06-01\"): 5,\n",
    "    pd.to_datetime(\"2017-07-01\"): 6, pd.to_datetime(\"2017-08-01\"): 7, pd.to_datetime(\"2017-09-01\"): 8,\n",
    "    pd.to_datetime(\"2017-10-01\"): 9, pd.to_datetime(\"2017-11-01\"): 10, pd.to_datetime(\"2017-12-01\"): 11,\n",
    "    pd.to_datetime(\"2018-01-01\"): 12, pd.to_datetime(\"2018-02-01\"): 13, pd.to_datetime(\"2018-03-01\"): 14,\n",
    "    pd.to_datetime(\"2018-04-01\"): 15, pd.to_datetime(\"2018-05-01\"): 16, pd.to_datetime(\"2018-06-01\"): 17,\n",
    "    pd.to_datetime(\"2018-07-01\"): 18, pd.to_datetime(\"2018-08-01\"): 19, pd.to_datetime(\"2018-09-01\"): 20,\n",
    "    pd.to_datetime(\"2018-10-01\"): 21, pd.to_datetime(\"2018-11-01\"): 22, pd.to_datetime(\"2018-12-01\"): 23,\n",
    "    pd.to_datetime(\"2019-01-01\"): 24, pd.to_datetime(\"2019-02-01\"): 25, pd.to_datetime(\"2019-03-01\"): 26,\n",
    "    pd.to_datetime(\"2019-04-01\"): 27, pd.to_datetime(\"2019-05-01\"): 28, pd.to_datetime(\"2019-06-01\"): 29,\n",
    "    pd.to_datetime(\"2019-07-01\"): 30, pd.to_datetime(\"2019-08-01\"): 31, pd.to_datetime(\"2019-09-01\"): 32,\n",
    "    pd.to_datetime(\"2019-10-01\"): 33, pd.to_datetime(\"2019-11-01\"): 34, pd.to_datetime(\"2019-12-01\"): 35\n",
    "}\n",
    "\n",
    "# Agregar la columna periodo_indice al DataFrame usando el mapeo\n",
    "df['periodo_indice'] = df['periodo_dt'].map(periodo_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego nuevas caracteristicas basadas en calendario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"]        = df[\"periodo_dt\"].dt.year.astype(\"int16\")\n",
    "df[\"month\"]       = df[\"periodo_dt\"].dt.month.astype(\"int8\")\n",
    "df[\"quarter\"]     = df[\"periodo_dt\"].dt.quarter.astype(\"int8\")\n",
    "df[\"month_idx\"]   = (df[\"year\"] * 12 + df[\"month\"]).astype(\"int32\")  # continuous index\n",
    "df[\"is_fy_start\"] = df[\"month\"].eq(1).astype(\"int8\")\n",
    "df[\"is_fy_end\"]   = df[\"month\"].eq(12).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Seasons  (southern hemisphere)\n",
    "#    Summer = Dec–Feb, Autumn = Mar–May, Winter = Jun–Aug, Spring = Sep–Nov\n",
    "# -----------------------------------------------------------\n",
    "season_map = {\n",
    "    12: \"summer\", 1: \"summer\", 2: \"summer\",\n",
    "    3:  \"autumn\", 4: \"autumn\", 5: \"autumn\",\n",
    "    6:  \"winter\", 7: \"winter\", 8: \"winter\",\n",
    "    9:  \"spring\", 10: \"spring\", 11: \"spring\",\n",
    "}\n",
    "\n",
    "df[\"season\"] = (\n",
    "    df[\"periodo_dt\"].dt.month.map(season_map)\n",
    "      .astype(\"category\")              # LightGBM friendly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER DE AGREGAR CARACTERISTICAS QUE INDIQUEN VACACIONES Y FERIADOS, NAVIDAD, ETC.\n",
    "# ar_holidays = holidays.AR()\n",
    "# for ptr in holidays.AR(years = 2018).items():\n",
    "#     p, int(ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGREGO MESES EXTRAÑOS EN EL DATASET\n",
    "\n",
    "Mes atípico:\n",
    "- Junio 2019\n",
    "- Agosto 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mes_anormal_1\"] = (\n",
    "    df[\"periodo_dt\"].dt.to_period(\"M\") == pd.Period(\"2019-08\", freq=\"M\")\n",
    ").astype(\"int8\")          # 1 para agosto-2019, 0 para el resto\n",
    "\n",
    "df[\"mes_anormal_2\"] = (\n",
    "    df[\"periodo_dt\"].dt.to_period(\"M\") == pd.Period(\"2019-06\", freq=\"M\")\n",
    ").astype(\"int8\")          # 1 para agosto-2019, 0 para el resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo clase y lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"product_id\",\"periodo_dt\"])\n",
    "\n",
    "# tn adelantado 2 periodos (h=2)\n",
    "df[\"clase\"] = (\n",
    "    df.groupby([\"product_id\"])[\"tn\"]\n",
    "      .shift(-2)          # -2 = lead de 2 meses\n",
    "      .astype(\"float32\")  # mismo tipo que tn para ahorrar RAM\n",
    ")\n",
    "\n",
    "# Generar columnas tn-1, tn-2, ..., tn-11 (12 meses de adelanto)\n",
    "for i in range(1, 36):\n",
    "    df[f\"tn-{i}\"] = (\n",
    "        df.groupby([\"product_id\"])[\"tn\"]\n",
    "          .shift(+i)          # -i = lead de i meses\n",
    "          .astype(\"float32\")  # mismo tipo que tn para ahorrar RAM\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling: media y desviación en ventana de 3,6 y 12 meses\n",
    "shift(1) para evitar \"ver el futuro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby([\"product_id\"])\n",
    "# ───────────────────────────────\n",
    "# Rolling: media y desviación en ventana de 3,6 y 12 meses\n",
    "# ───────────────────────────────\n",
    "window_sizes = [3, 6, 12]\n",
    "\n",
    "for w in window_sizes:\n",
    "    # Media móvil\n",
    "    df[f\"tn_roll_mean_{w}\"] = (\n",
    "        grp[\"tn\"]\n",
    "          .rolling(window=w)\n",
    "          .mean()\n",
    "          .shift(1)                       # deja fuera el mes actual\n",
    "          .reset_index(level=[0,1], drop=True)\n",
    "          .astype(\"float32\")\n",
    "    )\n",
    "    # Desviación estándar móvil\n",
    "    df[f\"tn_roll_std_{w}\"] = (\n",
    "        grp[\"tn\"]\n",
    "          .rolling(window=w)\n",
    "          .std()\n",
    "          .shift(1)\n",
    "          .reset_index(level=[0,1], drop=True)\n",
    "          .astype(\"float32\")\n",
    "    )\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 3. Opcional: rellenar NaN iniciales con 0 o dejarlos\n",
    "# ───────────────────────────────\n",
    "# lag_cols = [f\"tn_lag{l}\" for l in lag_list]\n",
    "roll_cols = [f\"tn_roll_mean_{w}\" for w in window_sizes] + \\\n",
    "            [f\"tn_roll_std_{w}\"  for w in window_sizes]\n",
    "\n",
    "df[roll_cols] = df[roll_cols].fillna(0)\n",
    "\n",
    "# Guardar si quieres\n",
    "# df.to_parquet(\"data/sell_in_fixed36_feats.parquet\", compression=\"zstd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28080 entries, 0 to 28079\n",
      "Data columns (total 64 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   product_id             28080 non-null  int32         \n",
      " 1   periodo_dt             28080 non-null  datetime64[ns]\n",
      " 2   plan_precios_cuidados  28080 non-null  int64         \n",
      " 3   cust_request_qty       28080 non-null  float64       \n",
      " 4   cust_request_tn        28080 non-null  float32       \n",
      " 5   tn                     28080 non-null  float32       \n",
      " 6   cat1                   28080 non-null  object        \n",
      " 7   cat2                   28080 non-null  object        \n",
      " 8   cat3                   28080 non-null  object        \n",
      " 9   brand                  28080 non-null  object        \n",
      " 10  sku_size               28080 non-null  int64         \n",
      " 11  descripcion            28080 non-null  object        \n",
      " 12  periodo_indice         28080 non-null  int64         \n",
      " 13  year                   28080 non-null  int16         \n",
      " 14  month                  28080 non-null  int8          \n",
      " 15  quarter                28080 non-null  int8          \n",
      " 16  month_idx              28080 non-null  int32         \n",
      " 17  is_fy_start            28080 non-null  int8          \n",
      " 18  is_fy_end              28080 non-null  int8          \n",
      " 19  season                 28080 non-null  category      \n",
      " 20  mes_anormal_1          28080 non-null  int8          \n",
      " 21  mes_anormal_2          28080 non-null  int8          \n",
      " 22  clase                  26520 non-null  float32       \n",
      " 23  tn-1                   27300 non-null  float32       \n",
      " 24  tn-2                   26520 non-null  float32       \n",
      " 25  tn-3                   25740 non-null  float32       \n",
      " 26  tn-4                   24960 non-null  float32       \n",
      " 27  tn-5                   24180 non-null  float32       \n",
      " 28  tn-6                   23400 non-null  float32       \n",
      " 29  tn-7                   22620 non-null  float32       \n",
      " 30  tn-8                   21840 non-null  float32       \n",
      " 31  tn-9                   21060 non-null  float32       \n",
      " 32  tn-10                  20280 non-null  float32       \n",
      " 33  tn-11                  19500 non-null  float32       \n",
      " 34  tn-12                  18720 non-null  float32       \n",
      " 35  tn-13                  17940 non-null  float32       \n",
      " 36  tn-14                  17160 non-null  float32       \n",
      " 37  tn-15                  16380 non-null  float32       \n",
      " 38  tn-16                  15600 non-null  float32       \n",
      " 39  tn-17                  14820 non-null  float32       \n",
      " 40  tn-18                  14040 non-null  float32       \n",
      " 41  tn-19                  13260 non-null  float32       \n",
      " 42  tn-20                  12480 non-null  float32       \n",
      " 43  tn-21                  11700 non-null  float32       \n",
      " 44  tn-22                  10920 non-null  float32       \n",
      " 45  tn-23                  10140 non-null  float32       \n",
      " 46  tn-24                  9360 non-null   float32       \n",
      " 47  tn-25                  8580 non-null   float32       \n",
      " 48  tn-26                  7800 non-null   float32       \n",
      " 49  tn-27                  7020 non-null   float32       \n",
      " 50  tn-28                  6240 non-null   float32       \n",
      " 51  tn-29                  5460 non-null   float32       \n",
      " 52  tn-30                  4680 non-null   float32       \n",
      " 53  tn-31                  3900 non-null   float32       \n",
      " 54  tn-32                  3120 non-null   float32       \n",
      " 55  tn-33                  2340 non-null   float32       \n",
      " 56  tn-34                  1560 non-null   float32       \n",
      " 57  tn-35                  780 non-null    float32       \n",
      " 58  tn_roll_mean_3         28080 non-null  float32       \n",
      " 59  tn_roll_std_3          28080 non-null  float32       \n",
      " 60  tn_roll_mean_6         28080 non-null  float32       \n",
      " 61  tn_roll_std_6          28080 non-null  float32       \n",
      " 62  tn_roll_mean_12        28080 non-null  float32       \n",
      " 63  tn_roll_std_12         28080 non-null  float32       \n",
      "dtypes: category(1), datetime64[ns](1), float32(44), float64(1), int16(1), int32(2), int64(3), int8(6), object(5)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borro columnas que no voy a usar\n",
    "columnas_a_borrar = [\"periodo_dt\", \"is_synth\", \"is_synth_36\"]\n",
    "df.drop(columns=columnas_a_borrar, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUARDO UN PRIMER DATASET EN BASE A ESTE NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_SALIDA='sell_in_03-featureaddv1.parquet\"'\n",
    "df.to_parquet(SALIDAS_DIR + FILE_NAME_SALIDA , compression=\"zstd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
