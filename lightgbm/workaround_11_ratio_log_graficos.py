# -*- coding: utf-8 -*-
"""
Generador de Visualizaciones de Series Temporales y Forecasts
=============================================================

Este script est谩 dise帽ado para generar visualizaciones detalladas de las series
temporales de ventas y las predicciones generadas por los modelos.

Funcionalidades principales:
- Carga los datos hist贸ricos y los archivos de predicci贸n (buscando el mejor
  ensamble disponible).
- Para cada producto a predecir, genera un gr谩fico que muestra:
  - La serie temporal hist贸rica de ventas.
  - La predicci贸n para el per铆odo objetivo (Febrero 2020).
  - Estad铆sticas clave y detalles del m茅todo de modelado.
- Compila todos los gr谩ficos individuales en un 煤nico archivo PDF para una
  revisi贸n consolidada.
- Genera un archivo de texto con un resumen del proceso de visualizaci贸n.

Par谩metros Principales de Configuraci贸n (dentro de la clase Config):
--------------------------------------------------------------------
- GRANULARITY: 'product' o 'customer'. Define el nivel de agregaci贸n.
- FEATURE_VERSION: Versi贸n de las features, para alinear con los artefactos
  de predicci贸n correctos.
- GRAFICOS_PATH: Directorio donde se guardar谩n los gr谩ficos y el PDF.

"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.backends.backend_pdf import PdfPages
import seaborn as sns
import logging
import warnings
from datetime import datetime
import glob
from typing import List, Optional

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')

class Config:
    GRANULARITY     = 'product'       # 'product' | 'customer'
    FEATURE_VERSION = 'v6_log_ratio_advanced'  # Alineado con workaround_11
    CACHE_PATH      = 'cache_log_ratio_advanced'
    ARTIFACTS_PATH  = 'artifacts_log_ratio_advanced'
    GRAFICOS_PATH  = os.path.join('artifacts_log_ratio_advanced', 'graficos')
    
    # URLs para descargar datos
    SELLIN_URL = 'https://storage.googleapis.com/open-courses/austral2025-af91/labo3v/sell-in.txt.gz'
    PRODUCTOS_URL = 'https://storage.googleapis.com/open-courses/austral2025-af91/labo3v/tb_productos.txt'
    PRODUCTOS_A_PREDECIR_URL = 'https://storage.googleapis.com/open-courses/austral2025-af91/labo3v/product_id_apredecir201912.txt'
    
    # Configuraci贸n de gr谩ficos
    FIGURE_SIZE = (15, 8)
    DPI = 150
    DATE_FORMAT = '%Y-%m'
    
def get_logger():
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s')
    return logging.getLogger()

logger = get_logger()

def calculate_birth_dates(cfg):
    """Calcula las fechas de nacimiento de productos y clientes."""
    logger.info("Calculando fechas de nacimiento...")
    
    # Cargar sellin para calcular fechas de nacimiento
    sellin = pd.read_csv(
        cfg.SELLIN_URL,
        sep="\t", 
        compression='gzip',
        dtype={'periodo': str, 'customer_id': str, 'product_id': str}
    )
    sellin['periodo'] = pd.to_datetime(sellin['periodo'], format='%Y%m')
    
    birth_dates = {}
    
    # Fecha de nacimiento de productos
    birth_dates['product'] = sellin.groupby('product_id')['periodo'].min().reset_index()
    birth_dates['product'].columns = ['product_id', 'birth_date_product']
    
    # Fecha de nacimiento de clientes
    birth_dates['customer'] = sellin.groupby('customer_id')['periodo'].min().reset_index()
    birth_dates['customer'].columns = ['customer_id', 'birth_date_customer']
    
    return birth_dates

def load_historical_data(cfg, birth_dates):
    """Carga datos hist贸ricos con filtro de fechas de nacimiento."""
    logger.info("Cargando datos hist贸ricos...")
    
    # Cargar datos principales
    sellin = pd.read_csv(
        cfg.SELLIN_URL,
        sep="\t", 
        compression='gzip',
        dtype={'periodo': str, 'customer_id': str, 'product_id': str}
    )
    sellin['periodo'] = pd.to_datetime(sellin['periodo'], format='%Y%m')
    
    productos = pd.read_csv(
        cfg.PRODUCTOS_URL,
        sep="\t", 
        dtype={'product_id': str}
    )
    
    # Agregar por granularidad
    gcols = ['periodo', 'product_id']
    if cfg.GRANULARITY == 'customer':
        gcols.append('customer_id')
    
    df = sellin.groupby(gcols)['tn'].sum().reset_index()
    
    # Crear grid completo
    periods = pd.date_range(sellin['periodo'].min(), sellin['periodo'].max(), freq='MS')
    products = sellin['product_id'].unique()
    
    if cfg.GRANULARITY == 'customer':
        customers = sellin['customer_id'].unique()
        grid = pd.MultiIndex.from_product([periods, products, customers],
                                          names=['periodo','product_id','customer_id'])
    else:
        grid = pd.MultiIndex.from_product([periods, products],
                                          names=['periodo','product_id'])
    
    df = df.set_index(gcols).reindex(grid, fill_value=0).reset_index()
    
    # Merge con productos para tener descripci贸n
    df = df.merge(productos, on='product_id', how='left')
    
    # Aplicar filtro de fechas de nacimiento
    df = df.merge(birth_dates['product'], on='product_id', how='left')
    
    if cfg.GRANULARITY == 'customer':
        df = df.merge(birth_dates['customer'], on='customer_id', how='left')
    
    # Filtrar registros anteriores a fecha de nacimiento
    initial_rows = len(df)
    df = df[df['periodo'] >= df['birth_date_product']]
    
    if cfg.GRANULARITY == 'customer':
        df = df[df['periodo'] >= df['birth_date_customer']]
    
    filtered_rows = initial_rows - len(df)
    logger.info(f"Filtrados {filtered_rows:,} registros no nacidos de {initial_rows:,} totales")
    
    # Eliminar columnas auxiliares
    cols_to_drop = ['birth_date_product']
    if cfg.GRANULARITY == 'customer':
        cols_to_drop.append('birth_date_customer')
    df = df.drop(columns=cols_to_drop)
    
    return df

def load_productos_a_predecir(cfg):
    """Carga la lista de productos a predecir."""
    logger.info("Cargando lista de productos a predecir...")
    productos_a_predecir = pd.read_csv(
        cfg.PRODUCTOS_A_PREDECIR_URL,
        sep='\t', 
        dtype={'product_id': str}
    )
    return productos_a_predecir

def find_best_ensemble_prediction(cfg):
    """Encuentra el mejor archivo de predicci贸n (ensemble prioritario, luego individual)."""
    # 1. Buscar ensemble prioritario (semiller铆o)
    ensemble_pattern = os.path.join(
        cfg.ARTIFACTS_PATH, 
        f'{cfg.GRANULARITY}_{cfg.FEATURE_VERSION}_semillerio_*.csv'
    )
    ensemble_files = glob.glob(ensemble_pattern)
    
    if ensemble_files:
        # Tomar el ensemble con m谩s modelos (n煤mero m谩s alto en el nombre)
        ensemble_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))
        best_file = ensemble_files[-1]
        logger.info(f"Usando predicci贸n ensemble: {os.path.basename(best_file)}")
        return best_file
    
    # 2. Si no hay ensemble, buscar submission individual
    single_pattern = os.path.join(
        cfg.ARTIFACTS_PATH, 
        f'submission_202002_{cfg.GRANULARITY}_{cfg.FEATURE_VERSION}.csv'
    )
    if os.path.exists(single_pattern):
        logger.info(f"Usando predicci贸n individual: {os.path.basename(single_pattern)}")
        return single_pattern
    
    # 3. Buscar cualquier submission con features avanzadas
    fallback_pattern = os.path.join(
        cfg.ARTIFACTS_PATH, 
        f'submission_202002_{cfg.GRANULARITY}_*advanced*.csv'
    )
    fallback_files = glob.glob(fallback_pattern)
    if fallback_files:
        best_file = fallback_files[0]  # Tomar el primero
        logger.info(f" Usando predicci贸n fallback: {os.path.basename(best_file)}")
        return best_file
    
    logger.error("No se encontr贸 ning煤n archivo de predicci贸n")
    logger.error("Ejecuta primero workaround_11_ratio_log.py o workaround_11_semillerio_ratio_log.py")
    return None

def prepare_time_series_data(df, cfg):
    """Prepara los datos de series temporales por producto."""
    logger.info("Preparando datos de series temporales...")
    
    if cfg.GRANULARITY == 'customer':
        # Agregar por producto
        ts_data = df.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()
    else:
        ts_data = df[['periodo', 'product_id', 'tn']].copy()
    
    # Tambi茅n incluir descripci贸n del producto
    productos_info = df[['product_id', 'descripcion']].drop_duplicates()
    ts_data = ts_data.merge(productos_info, on='product_id', how='left')
    
    return ts_data

def create_product_chart(product_data, prediction_value, product_info, cfg):
    """Crea un gr谩fico mejorado para un producto espec铆fico y devuelve la figura."""
    
    fig, ax = plt.subplots(figsize=cfg.FIGURE_SIZE, dpi=cfg.DPI)
    
    # Datos hist贸ricos
    x_dates = product_data['periodo']
    y_values = product_data['tn']
    
    # L铆nea principal de la serie temporal con estilo mejorado
    ax.plot(x_dates, y_values, linewidth=2.8, color='steelblue', alpha=0.9, 
            label='Ventas Hist贸ricas', marker='o', markersize=3, markerfacecolor='navy', markeredgewidth=0)
    
    # rea bajo la curva para mejor visualizaci贸n
    ax.fill_between(x_dates, y_values, alpha=0.25, color='lightblue')

    # Etiqueta para el 煤ltimo valor de la serie
    if not y_values.empty:
        last_date = x_dates.iloc[-1]
        last_value = y_values.iloc[-1]
        ax.text(last_date, last_value, f'{last_value:.3g}', 
                ha='center', va='bottom', fontsize=10, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.7, edgecolor='orange'))
    
    # Punto de predicci贸n con estilo mejorado
    pred_date = pd.to_datetime('2020-02-01')
    ax.scatter([pred_date], [prediction_value], color='red', s=150, zorder=5, 
               label=f'Predicci贸n Feb 2020: {prediction_value:.2f} tn',
               marker='D', edgecolors='darkred', linewidth=2)

    # Etiqueta para el valor de la predicci贸n con mejor posicionamiento
    offset = (ax.get_ylim()[1] - ax.get_ylim()[0]) * 0.03
    ax.text(pred_date, prediction_value + offset, f'{prediction_value:.3g}', 
            ha='center', va='bottom', fontsize=10, fontweight='bold', color='darkred',
            bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='red', alpha=0.8))
    
    # L铆nea vertical indicando la predicci贸n
    ax.axvline(x=pred_date, color='red', linestyle='--', alpha=0.6, linewidth=2)
    
    # Configuraci贸n de ejes mejorada
    ax.set_xlabel('Per铆odo', fontsize=13, fontweight='bold')
    ax.set_ylabel('Toneladas Vendidas', fontsize=13, fontweight='bold')
    
    # T铆tulo con informaci贸n del producto
    product_id = product_info['product_id']
    descripcion = product_info['descripcion']
    
    # Truncar descripci贸n si es muy larga
    if len(descripcion) > 55:
        descripcion = descripcion[:52] + "..."
    
    title = f'Producto: {product_id} | Features Avanzadas v11\n{descripcion}'
    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)
    
    # Formato de fechas en eje X mejorado
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.xaxis.set_minor_locator(mdates.MonthLocator((1, 4, 7, 10)))  # Cada trimestre
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%m'))
    
    # Rotar etiquetas para mejor legibilidad
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center', fontweight='bold')
    
    # Grid mejorado
    ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5)
    ax.set_axisbelow(True)
    
    # Leyenda mejorada
    ax.legend(loc='upper left', frameon=True, fancybox=True, shadow=True, 
              fontsize=11, framealpha=0.9)
    
    # Estad铆sticas en el gr谩fico con mejor formato
    max_val = y_values.max()
    min_val = y_values.min()
    mean_val = y_values.mean()
    std_val = y_values.std()
    
    stats_text = (f'Estad铆sticas Hist贸ricas:\n'
                  f'M谩x: {max_val:.2f} tn\n'
                  f'Min: {min_val:.2f} tn\n'
                  f'Promedio: {mean_val:.2f} tn\n'
                  f'Std Dev: {std_val:.2f} tn')
    
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', 
            bbox=dict(boxstyle='round,pad=0.5', facecolor='wheat', alpha=0.85, edgecolor='brown'))
    
    # Informaci贸n adicional sobre el m茅todo
    method_text = ('M茅todo: Log-ratio + Features Avanzadas\n'
                   'Cache: Nivel 3 (_ii)\n'
                   'Categor铆as: 3 niveles + Brand\n'
                   'Estacionalidad: Fourier + Eventos')
    
    ax.text(0.98, 0.02, method_text, transform=ax.transAxes, fontsize=9,
            verticalalignment='bottom', horizontalalignment='right',
            bbox=dict(boxstyle='round,pad=0.4', facecolor='lightcyan', alpha=0.8, edgecolor='teal'))
    
    # Ajustar layout
    plt.tight_layout()
    
    return fig

def generate_visualizations(ts_data, predictions, productos_a_predecir, cfg):
    """Genera todas las visualizaciones y el PDF con mejoras."""
    
    logger.info("Generando visualizaciones avanzadas...")
    
    # Crear directorio de gr谩ficos
    os.makedirs(cfg.GRAFICOS_PATH, exist_ok=True)
    
    # Lista para almacenar rutas de im谩genes
    image_paths = []
    productos_procesados = 0
    productos_sin_datos = 0
    productos_sin_prediccion = 0
    
    # PDF para compilar todas las im谩genes
    pdf_path = os.path.join(cfg.GRAFICOS_PATH, f'series_temporales_{cfg.GRANULARITY}_advanced.pdf')
    
    with PdfPages(pdf_path) as pdf:
        for i, row in enumerate(productos_a_predecir.iterrows()):
            _, row_data = row
            product_id = row_data['product_id']
            
            # Obtener datos hist贸ricos del producto
            product_data = ts_data[ts_data['product_id'] == product_id].copy()
            
            if product_data.empty:
                logger.debug(f"No hay datos hist贸ricos para producto {product_id}")
                productos_sin_datos += 1
                continue
            
            # Obtener predicci贸n
            pred_row = predictions[predictions['product_id'] == product_id]
            if pred_row.empty:
                logger.debug(f"No hay predicci贸n para producto {product_id}")
                productos_sin_prediccion += 1
                continue
            
            prediction_value = pred_row['tn'].iloc[0]
            
            # Informaci贸n del producto
            product_info = {
                'product_id': product_id,
                'descripcion': product_data['descripcion'].iloc[0] if not product_data['descripcion'].isna().all() 
                              else f'Producto {product_id}'
            }
            
            # Ruta para guardar la imagen
            image_filename = f'producto_{product_id}_advanced.png'
            image_path = os.path.join(cfg.GRAFICOS_PATH, image_filename)
            
            # Crear gr谩fico mejorado (la funci贸n ahora devuelve la figura)
            fig = create_product_chart(product_data, prediction_value, product_info, cfg)
            
            # Guardar la figura en formato PNG
            fig.savefig(image_path, dpi=cfg.DPI, bbox_inches='tight', facecolor='white',
                       edgecolor='none', pad_inches=0.1)
            
            # Guardar la misma figura en el PDF
            pdf.savefig(fig, bbox_inches='tight', facecolor='white', edgecolor='none')
            
            # Cerrar la figura para liberar memoria
            plt.close(fig)
            
            image_paths.append(image_path)
            productos_procesados += 1
            
            if (i + 1) % 100 == 0:
                logger.info(f"Procesados {productos_procesados} de {len(productos_a_predecir)} productos...")
    
    logger.info(f"Visualizaciones completadas:")
    logger.info(f"  Productos procesados: {productos_procesados}")
    logger.info(f"  Productos sin datos: {productos_sin_datos}")
    logger.info(f"  Productos sin predicci贸n: {productos_sin_prediccion}")
    logger.info(f"  Im谩genes generadas: {len(image_paths)}")
    logger.info(f"  PDF compilado: {pdf_path}")
    
    # Generar archivo de resumen mejorado
    summary_path = os.path.join(cfg.GRAFICOS_PATH, 'resumen_visualizaciones_advanced.txt')
    with open(summary_path, 'w') as f:
        f.write(f"Resumen Visualizaciones - Features Avanzadas v11\n")
        f.write("="*70 + "\n")
        f.write(f"Granularidad: {cfg.GRANULARITY}\n")
        f.write(f"Feature Version: {cfg.FEATURE_VERSION}\n")
        f.write(f"Cache Level: Nivel 3 (_ii) - Features Avanzadas\n")
        f.write(f"Estrategia: y = log1p(tn_future) - log1p(tn_current) + Advanced Features\n")
        f.write(f"Fecha generaci贸n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total productos a predecir: {len(productos_a_predecir)}\n")
        f.write(f"Productos procesados: {productos_procesados}\n")
        f.write(f"Productos sin datos hist贸ricos: {productos_sin_datos}\n")
        f.write(f"Productos sin predicci贸n: {productos_sin_prediccion}\n")
        f.write(f"Per铆odo hist贸rico: 2017-01 a 2019-12\n")
        f.write(f"Predicci贸n para: 2020-02\n")
        f.write(f"\nFeatures Avanzadas Implementadas:\n")
        f.write(f"- A. Productos Relacionados: contexto 3 niveles categor铆as\n")
        f.write(f"- B. Estacionalidad Avanzada: fourier + eventos argentinos\n")
        f.write(f"- C. Momentum/Aceleraci贸n: slopes + cambios volatilidad\n")
        f.write(f"- D. Patrones Consumo: skewness + regularidad temporal\n")
        f.write(f"\nArchivos generados:\n")
        f.write(f"  - PDF compilado: {os.path.basename(pdf_path)}\n")
        f.write(f"  - Im谩genes individuales: {len(image_paths)} archivos PNG\n")
        f.write(f"\nUso recomendado:\n")
        f.write(f"  - Revisar PDF para an谩lisis secuencial completo\n")
        f.write(f"  - Usar PNG individuales para consultas a LLM multimodal\n")
        f.write(f"  - Validar razonabilidad de predicciones con features avanzadas\n")
        f.write(f"  - Comparar vs. versiones anteriores para evaluar mejoras\n")
        f.write(f"\nObjetivo:\n")
        f.write(f"  - Superar meseta de optimizaci贸n con features de alto impacto\n")
        f.write(f"  - Reducir Total Error Rate mediante contexto categorial\n")
        f.write(f"  - Mejorar captaci贸n de patrones estacionales complejos\n")
    
    return image_paths, pdf_path

def main():
    logger.info("INICIANDO GRFICOS - FEATURES AVANZADAS v11")
    
    cfg = Config()
    
    # Crear directorios
    for p in [cfg.CACHE_PATH, cfg.ARTIFACTS_PATH, cfg.GRAFICOS_PATH]:
        os.makedirs(p, exist_ok=True)
    
    # Cargar datos necesarios
    logger.info("--- FASE 1: Cargando Datos ---")
    birth_dates = calculate_birth_dates(cfg)
    historical_data = load_historical_data(cfg, birth_dates)
    productos_a_predecir = load_productos_a_predecir(cfg)
    
    # Preparar series temporales
    logger.info("--- FASE 2: Preparando Series Temporales ---")
    ts_data = prepare_time_series_data(historical_data, cfg)
    
    # Cargar predicciones
    logger.info("--- FASE 3: Cargando Predicciones Avanzadas ---")
    prediction_file = find_best_ensemble_prediction(cfg)
    if prediction_file is None:
        logger.error("No se pudo encontrar archivo de predicciones")
        logger.error("Ejecuta primero workaround_11_ratio_log.py o workaround_11_semillerio_ratio_log.py")
        return
    
    predictions = pd.read_csv(prediction_file, dtype={'product_id': str})
    logger.info(f"Predicciones cargadas: {len(predictions)} productos")
    logger.info(f"Total predicho: {predictions['tn'].sum():,.2f} toneladas")
    
    # Generar visualizaciones
    logger.info("--- FASE 4: Generando Visualizaciones Avanzadas ---")
    image_paths, pdf_path = generate_visualizations(ts_data, predictions, productos_a_predecir, cfg)
    
    logger.info("\nGENERACIN GRFICOS AVANZADOS COMPLETADA")
    logger.info(f" Archivos generados en: {cfg.GRAFICOS_PATH}")
    logger.info(f"PDF compilado: {os.path.basename(pdf_path)}")
    logger.info(f"Im谩genes individuales: {len(image_paths)} archivos PNG")
    logger.info("\nUso sugerido:")
    logger.info("  Revisar PDF para an谩lisis secuencial de features avanzadas")
    logger.info("  Usar PNG para consultas espec铆ficas a LLM multimodal")
    logger.info("  Validar mejoras vs. versiones anteriores")
    logger.info("  Evaluar impacto de features A+B+C+D en predicciones")
    logger.info("Objetivo: Verificar que features avanzadas mejoran calidad predictiva")

if __name__ == '__main__':
    main()