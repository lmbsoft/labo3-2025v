{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef712540",
   "metadata": {},
   "source": [
    "# üè≠ Pipeline de Forecasting por Producto usando AutoGluon\n",
    "\n",
    "En este notebook vamos a entrenar y validar modelos de series temporales por producto (`product_id`), prediciendo las toneladas vendidas (`tn`) a 2 per√≠odos hacia adelante. Se incluyen variables adicionales y se eval√∫a el uso de AutoGluon para forecasting multivariante.\n",
    "\n",
    "- **Entrada:** parquet `\"dataset_product_periodo.parquet\"`\n",
    "- **Objetivo:** predecir `tn` para cada producto en el per√≠odo `202002` (`M+2` respecto al √∫ltimo dato disponible).\n",
    "- **Salida:** CSV con columnas `product_id` y `tn` (pronosticado para `202002`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29163d0",
   "metadata": {},
   "source": [
    "## üî¢ Celda de c√≥digo ‚Äì Carga de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8728013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librer√≠as principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160ec0b",
   "metadata": {},
   "source": [
    "## üì¶ Carga y preprocesamiento de datos\n",
    "\n",
    "Levantamos el archivo parquet generado en la etapa anterior, verificamos la estructura y visualizamos los primeros registros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "716ec127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn_total</th>\n",
       "      <th>clientes_positivos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>fecha</th>\n",
       "      <th>mm-yyyy</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>201701</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>186</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01-2017</td>\n",
       "      <td>2017Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>201702</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>185</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>02-2017</td>\n",
       "      <td>2017Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>201703</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>188</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>03-2017</td>\n",
       "      <td>2017Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>201704</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>104</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>04-2017</td>\n",
       "      <td>2017Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>201705</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>238</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>05-2017</td>\n",
       "      <td>2017Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id periodo    tn_total  clientes_positivos cat1         cat2  \\\n",
       "0       20001  201701   934.77222                 186   HC  ROPA LAVADO   \n",
       "1       20001  201702   798.01620                 185   HC  ROPA LAVADO   \n",
       "2       20001  201703  1303.35771                 188   HC  ROPA LAVADO   \n",
       "3       20001  201704  1069.96130                 104   HC  ROPA LAVADO   \n",
       "4       20001  201705  1502.20132                 238   HC  ROPA LAVADO   \n",
       "\n",
       "      cat3  brand  sku_size descripcion      fecha  mm-yyyy quarter  \n",
       "0  Liquido  ARIEL    3000.0      genoma 2017-01-01  01-2017  2017Q1  \n",
       "1  Liquido  ARIEL    3000.0      genoma 2017-02-01  02-2017  2017Q1  \n",
       "2  Liquido  ARIEL    3000.0      genoma 2017-03-01  03-2017  2017Q1  \n",
       "3  Liquido  ARIEL    3000.0      genoma 2017-04-01  04-2017  2017Q2  \n",
       "4  Liquido  ARIEL    3000.0      genoma 2017-05-01  05-2017  2017Q2  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruta_parquet = \"C:/Developer/Laboratorio_III/data/dataset_product_periodo.parquet\"\n",
    "df = pd.read_parquet(ruta_parquet)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f0633",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Preparaci√≥n de datos para AutoGluon\n",
    "\n",
    "AutoGluon espera los datos en formato *long* con columnas:\n",
    "\n",
    "- `item_id` (identificador de la serie, aqu√≠: `product_id`)\n",
    "- `timestamp` (fecha o per√≠odo, tipo datetime)\n",
    "- `target` (variable a predecir, aqu√≠: `tn_total`)\n",
    "- Variables adicionales opcionales (features, por ejemplo: `clientes_positivos`, `cat1`, `quarter`, etc.)\n",
    "\n",
    "Reformateamos y seleccionamos columnas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86435e8",
   "metadata": {},
   "source": [
    "### üìÑ Celda de c√≥digo ‚Äì Reformateo para AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "227b2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['periodo',\n",
       " 'clientes_positivos',\n",
       " 'cat1',\n",
       " 'cat2',\n",
       " 'cat3',\n",
       " 'brand',\n",
       " 'sku_size',\n",
       " 'descripcion',\n",
       " 'mm-yyyy',\n",
       " 'quarter']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renombrar columnas seg√∫n lo esperado por AutoGluon\n",
    "df_ag = df.rename(columns={\n",
    "    'product_id': 'item_id',\n",
    "    'fecha': 'timestamp',\n",
    "    'tn_total': 'target'\n",
    "})\n",
    "\n",
    "# Convertir timestamp a datetime si es necesario\n",
    "if not np.issubdtype(df_ag['timestamp'].dtype, np.datetime64):\n",
    "    df_ag['timestamp'] = pd.to_datetime(df_ag['timestamp'])\n",
    "\n",
    "# Definir las features adicionales (todas menos las esenciales)\n",
    "exclude = ['item_id', 'timestamp', 'target']\n",
    "features = [col for col in df_ag.columns if col not in exclude]\n",
    "\n",
    "# Seleccionar solo las columnas necesarias\n",
    "df_ag = df_ag[['item_id', 'timestamp', 'target'] + features]\n",
    "df_ag = df_ag.sort_values(['item_id', 'timestamp'])\n",
    "df_ag.head()\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ab4fc",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Celda de c√≥digo ‚Äì Entrenamiento del predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'c:\\Developer\\Laboratorio_III\\notebooks\\autogluon_forecasting_product'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          14\n",
      "GPU Count:          0\n",
      "Memory Avail:       3.57 GB / 15.31 GB (23.3%)\n",
      "Disk Space Avail:   234.59 GB / 475.95 GB (49.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'M',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': ['periodo',\n",
      "                            'clientes_positivos',\n",
      "                            'cat1',\n",
      "                            'cat2',\n",
      "                            'cat3',\n",
      "                            'brand',\n",
      "                            'sku_size',\n",
      "                            'descripcion',\n",
      "                            'mm-yyyy',\n",
      "                            'quarter'],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'M'.\n",
      "Provided train_data has 31522 rows, 1233 time series. Median time series length is 31 (min=1, max=36). \n",
      "\tRemoving 132 short time series from train_data. Only series with length >= 7 will be used for training.\n",
      "\tAfter filtering, train_data has 31021 rows, 1101 time series. Median time series length is 36 (min=7, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['periodo', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\t\tcontinuous (float): ['clientes_positivos', 'sku_size']\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['mm-yyyy', 'quarter']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-06-16 14:48:56\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.7s of the 3597.1s of remaining time.\n",
      "\t-1.6694       = Validation score (-MASE)\n",
      "\t0.03    s     = Training runtime\n",
      "\t6.65    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.2s of the 3590.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-1.7547       = Validation score (-MASE)\n",
      "\t1.66    s     = Training runtime\n",
      "\t0.08    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.2s of the 3588.6s of remaining time.\n",
      "\t-0.6218       = Validation score (-MASE)\n",
      "\t1.92    s     = Training runtime\n",
      "\t0.11    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 358.7s of the 3586.6s of remaining time.\n",
      "\t-1.7974       = Validation score (-MASE)\n",
      "\t0.04    s     = Training runtime\n",
      "\t0.63    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 398.4s of the 3585.9s of remaining time.\n",
      "\t-1.5079       = Validation score (-MASE)\n",
      "\t0.03    s     = Training runtime\n",
      "\t4.55    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 447.7s of the 3581.3s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 52 time series (4.7%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-1.5494       = Validation score (-MASE)\n",
      "\t0.04    s     = Training runtime\n",
      "\t3.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 511.2s of the 3578.1s of remaining time.\n",
      "\t-1.4751       = Validation score (-MASE)\n",
      "\t0.03    s     = Training runtime\n",
      "\t6.24    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 595.3s of the 3571.8s of remaining time.\n"
     ]
    }
   ],
   "source": [
    "# Determinamos el horizonte de predicci√≥n\n",
    "prediction_length = 2\n",
    "\n",
    "# Directorio de trabajo para AutoGluon\n",
    "output_directory = \"autogluon_forecasting_product\"\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    target='target',\n",
    "    prediction_length=prediction_length,\n",
    "    eval_metric='MASE',\n",
    "    path=output_directory,\n",
    "    known_covariates_names=features,  # ‚úÖ nombre correcto y lugar correcto\n",
    "    freq='M'  # üß† frecuencia mensual expl√≠cita\n",
    ")\n",
    "\n",
    "\n",
    "# Entrenar con todas las features excepto las excluidas\n",
    "predictor.fit(\n",
    "    train_data=df_ag,\n",
    "    time_limit=3600  # ahora queda solo esto ac√°\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbdd59",
   "metadata": {},
   "source": [
    "## üîÆ Predicci√≥n para productos objetivo en per√≠odo 202002\n",
    "\n",
    "Predecimos `tn` para cada producto en el per√≠odo `202002` (febrero 2020). Extraemos y guardamos el resultado en CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3d362",
   "metadata": {},
   "source": [
    "### üì• Celda de c√≥digo ‚Äì Cargar IDs desde archivo .txt con encabezado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f10178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Se cargar√°n 780 productos para predicci√≥n\n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo con encabezado \"product_id\"\n",
    "ruta_ids = \"C:/Developer/Laboratorio_III/data/product_id_apredecir201912.txt\"\n",
    "\n",
    "# Cargar los IDs respetando el encabezado\n",
    "df_ids = pd.read_csv(ruta_ids, sep=',')  # O ajustar sep si es tabulado\n",
    "product_ids_a_predecir = df_ids['product_id'].unique().tolist()\n",
    "\n",
    "# Verificamos\n",
    "print(f\"‚úÖ Se cargar√°n {len(product_ids_a_predecir)} productos para predicci√≥n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05ce6f",
   "metadata": {},
   "source": [
    "### üì• Celda de c√≥digo ‚Äì Cargar enriquecer los datos de entrada a la predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d853af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'MS' has been resampled to frequency 'M'.\n",
      "data with frequency 'MS' has been resampled to frequency 'M'.\n",
      "Model not specified in predict, will default to the model with the best validation score: DirectTabular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predicciones generadas y guardadas en pronostico_productos_202002_enriquecido.csv\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame\n",
    "\n",
    "# ----------------------------\n",
    "# 1Ô∏è‚É£ Cargar lista de productos a predecir\n",
    "# ----------------------------\n",
    "ruta_ids = \"C:/Developer/Laboratorio_III/data/product_id_apredecir201912.txt\"\n",
    "df_ids = pd.read_csv(ruta_ids, sep='\\t')  # Asegurate que el separador sea correcto\n",
    "df_ids.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "ids_pred = df_ids['item_id'].unique()\n",
    "\n",
    "# ----------------------------\n",
    "# 2Ô∏è‚É£ Filtrar historial hasta 2019-12-31 para los productos a predecir\n",
    "# ----------------------------\n",
    "historico = df_ag[\n",
    "    (df_ag['item_id'].isin(ids_pred)) &\n",
    "    (df_ag['timestamp'] <= '2019-12-31')\n",
    "].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# 3Ô∏è‚É£ Convertir historial a TimeSeriesDataFrame\n",
    "# ----------------------------\n",
    "required_columns = ['item_id', 'timestamp', 'target'] + features\n",
    "historico = historico[required_columns].copy()\n",
    "\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    historico,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4Ô∏è‚É£ Generar fechas futuras para el horizonte de predicci√≥n\n",
    "# ----------------------------\n",
    "df_future = predictor.make_future_data_frame(ts_data)\n",
    "\n",
    "# ----------------------------\n",
    "# 5Ô∏è‚É£ Preparar covariables para fechas futuras\n",
    "# ----------------------------\n",
    "# Extraemos las features que son est√°ticas por item_id (sin target ni timestamp)\n",
    "df_static = df_ag[df_ag['item_id'].isin(ids_pred)] \\\n",
    "    .drop(columns=['target', 'timestamp']) \\\n",
    "    .drop_duplicates(subset='item_id')\n",
    "\n",
    "# Combinamos con fechas futuras\n",
    "df_future_covs = df_future.merge(df_static, on='item_id', how='left')\n",
    "\n",
    "# ----------------------------\n",
    "# 6Ô∏è‚É£ Convertimos covariables a TimeSeriesDataFrame\n",
    "# ----------------------------\n",
    "known_cov_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_future_covs,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7Ô∏è‚É£ Predecimos\n",
    "# ----------------------------\n",
    "forecast_df = predictor.predict(\n",
    "    data=ts_data,\n",
    "    known_covariates=known_cov_tsdf\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8Ô∏è‚É£ Filtramos resultados para 2020-02-01 y exportamos\n",
    "# ----------------------------\n",
    "forecast_202002 = forecast_df.reset_index().query(\"timestamp == '2020-02-29'\")\n",
    "forecast_202002[['item_id', 'mean']] \\\n",
    "    .rename(columns={'item_id': 'product_id', 'mean': 'tn'}) \\\n",
    "    .to_csv('pronostico_productos_202002_enriquecido.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Predicciones generadas y guardadas en pronostico_productos_202002_enriquecido.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2ff85",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Conclusi√≥n\n",
    "\n",
    "El pipeline est√° listo para experimentar con variantes de features, ajustes de modelos y predicci√≥n autom√°tica de ventas por producto para cualquier horizonte.\n",
    "\n",
    "- Pod√©s repetir el pipeline para otros per√≠odos o conjuntos de productos.\n",
    "- Se pueden agregar rolling windows, rezagos, estacionalidad, o features macroecon√≥micos adicionales para mejorar el modelo.\n",
    "\n",
    "¬øListo para modelar y experimentar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92a212",
   "metadata": {},
   "source": [
    "## üìà Visualizaci√≥n y m√©tricas de resultados por producto\n",
    "\n",
    "Analizamos la performance del modelo por producto, visualizando ventas reales vs. pronosticadas y calculando m√©tricas de error relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2201f6",
   "metadata": {},
   "source": [
    "### üìâ Celda de c√≥digo ‚Äì Graficar reales vs. pronosticados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b1f277c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso: graficar para los primeros 3 productos\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m df_ag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[:\u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m---> 21\u001b[0m     plot_real_vs_pred(pid, df_ag, \u001b[43mforecast\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'forecast' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suponiendo que forecast contiene todas las predicciones para todos los per√≠odos\n",
    "# Y df_ag contiene los reales\n",
    "def plot_real_vs_pred(product_id, df_real, df_forecast):\n",
    "    real = df_real[df_real['item_id'] == product_id].set_index('timestamp')\n",
    "    pred = df_forecast[df_forecast.index.get_level_values('item_id') == product_id]\n",
    "    pred = pred.set_index('timestamp')\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(real['target'], label='Real', marker='o')\n",
    "    plt.plot(pred['mean'], label='Pronosticado', marker='x', linestyle='--')\n",
    "    plt.title(f'Producto {product_id} - Real vs Pron√≥stico')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Toneladas')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso: graficar para los primeros 3 productos\n",
    "for pid in df_ag['item_id'].unique()[:3]:\n",
    "    plot_real_vs_pred(pid, df_ag, forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83837746",
   "metadata": {},
   "source": [
    "### üßÆ Celda de c√≥digo ‚Äì M√©tricas de error por producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b92cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No se encontraron productos con predicciones para los timestamps esperados.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# ‚úÖ Conversi√≥n correcta\n",
    "df_real = pd.DataFrame(ts_data).reset_index()\n",
    "df_forecast = forecast_df.reset_index()\n",
    "\n",
    "metrics = []\n",
    "for pid in df_real['item_id'].unique():\n",
    "    real = df_real[df_real['item_id'] == pid].set_index('timestamp')\n",
    "    pred = df_forecast[df_forecast['item_id'] == pid].set_index('timestamp')\n",
    "\n",
    "    comunes = real.index.intersection(pred.index)\n",
    "    if len(comunes) > 0:\n",
    "        y_true = real.loc[comunes, 'target']\n",
    "        y_pred = pred.loc[comunes, 'mean']\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        wape = y_true.sub(y_pred).abs().sum() / y_true.sum()\n",
    "        metrics.append({'product_id': pid, 'MAE': mae, 'MAPE': mape, 'WAPE': wape})\n",
    "\n",
    "if not metrics:\n",
    "    print(\"‚ö†Ô∏è No se encontraron productos con predicciones para los timestamps esperados.\")\n",
    "else:\n",
    "    df_metrics = pd.DataFrame(metrics)\n",
    "    print(df_metrics.sort_values('WAPE', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9651f",
   "metadata": {},
   "source": [
    "## üåü Importancia de caracter√≠sticas y LeaderBoard de modelos\n",
    "\n",
    "A continuaci√≥n analizamos la importancia de variables del modelo seleccionado y visualizamos el desempe√±o de los modelos entrenados en AutoGluon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c1be783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'IRREG' has been resampled to frequency 'M'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot reserve last 2 time steps for evaluation in some time series in data. Please make sure that data includes both historical and future data, and thatall time series have length > prediction_length (at least 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importancia de caracter√≠sticas del mejor modelo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m display(feature_importance)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# LeaderBoard de modelos entrenados\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FSONZOGNI\\AppData\\Local\\anaconda3\\envs\\labo_III\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:1047\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.feature_importance\u001b[1;34m(self, data, model, metric, features, time_limit, method, subsample_size, num_iterations, random_seed, relative_scores, include_confidence_band, confidence_level)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1046\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_prepare_data_frame(data)\n\u001b[1;32m-> 1047\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_and_prepare_data_frame_for_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1049\u001b[0m fi_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mget_feature_importance(\n\u001b[0;32m   1050\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1051\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     confidence_level\u001b[38;5;241m=\u001b[39mconfidence_level,\n\u001b[0;32m   1062\u001b[0m )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fi_df\n",
      "File \u001b[1;32mc:\\Users\\FSONZOGNI\\AppData\\Local\\anaconda3\\envs\\labo_III\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:340\u001b[0m, in \u001b[0;36mTimeSeriesPredictor._check_and_prepare_data_frame_for_evaluation\u001b[1;34m(self, data, cutoff, name)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mnum_timesteps_per_item()\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m expected_length:\n\u001b[0;32m    339\u001b[0m     var_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expected_length \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reserve last \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m time steps for evaluation in some \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime series in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure that \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m includes both historical and future data, and that\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall time series have length > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cutoff \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length:\n\u001b[0;32m    347\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mslice_by_timestep(\u001b[38;5;28;01mNone\u001b[39;00m, cutoff \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot reserve last 2 time steps for evaluation in some time series in data. Please make sure that data includes both historical and future data, and thatall time series have length > prediction_length (at least 3)"
     ]
    }
   ],
   "source": [
    "# Importancia de caracter√≠sticas del mejor modelo\n",
    "feature_importance = predictor.feature_importance(df_ag)\n",
    "display(feature_importance)\n",
    "\n",
    "# LeaderBoard de modelos entrenados\n",
    "lb = predictor.leaderboard(df_ag, silent=True)\n",
    "display(lb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_III",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
