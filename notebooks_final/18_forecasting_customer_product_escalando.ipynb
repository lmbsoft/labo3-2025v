{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfd9ae5-edee-452b-929f-d13eecb983d2",
   "metadata": {},
   "source": [
    "# Modelado tabular con Autgluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba6e856-5142-4c55-9453-e7cd9cb05c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease\n",
      "Hit:2 https://deb.debian.org/debian bullseye InRelease              \n",
      "Hit:3 https://download.docker.com/linux/debian bullseye InRelease   \n",
      "Hit:4 https://deb.debian.org/debian-security bullseye-security InRelease\n",
      "Hit:5 https://deb.debian.org/debian bullseye-updates InRelease\n",
      "Hit:6 https://deb.debian.org/debian bullseye-backports InRelease\n",
      "Hit:7 https://packages.cloud.google.com/apt gcsfuse-bullseye InRelease\n",
      "Hit:8 https://packages.cloud.google.com/apt google-compute-engine-bullseye-stable InRelease\n",
      "Hit:9 https://packages.cloud.google.com/apt cloud-sdk-bullseye InRelease\n",
      "Hit:10 https://packages.cloud.google.com/apt google-fast-socket InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "gcsfuse is already the newest version (3.1.0).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install gcsfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafae9d5-f167-4844-a54d-837399e5957d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install autogluon.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714f161-c384-4582-9df4-b2e170562023",
   "metadata": {},
   "source": [
    "# Carga librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a34db802-71e7-4536-8484-73281601d474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80944f5-a7ef-4f3f-a194-ca859daa6053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ddf2a47-869b-4059-ab6a-93745c17b19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!fusermount -u /home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "165665a4-ea68-48fa-ae69-2dc8e0cd0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":{\"seconds\":1752536718,\"nanos\":520581833},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/3.1.0 (Go version go1.24.0) for app \\\"\\\" using mount point: /home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando\\n\"}\n",
      "{\"timestamp\":{\"seconds\":1752536718,\"nanos\":520621282},\"severity\":\"INFO\",\"message\":\"GCSFuse config\",\"config\":{\"AppName\":\"\",\"CacheDir\":\"\",\"Debug\":{\"ExitOnInvariantViolation\":false,\"Fuse\":false,\"Gcs\":false,\"LogMutex\":false},\"DisableAutoconfig\":false,\"EnableAtomicRenameObject\":true,\"EnableGoogleLibAuth\":false,\"EnableHns\":true,\"EnableNewReader\":false,\"FileCache\":{\"CacheFileForRangeRead\":false,\"DownloadChunkSizeMb\":200,\"EnableCrc\":false,\"EnableODirect\":false,\"EnableParallelDownloads\":false,\"ExperimentalExcludeRegex\":\"\",\"ExperimentalParallelDownloadsDefaultOn\":true,\"MaxParallelDownloads\":96,\"MaxSizeMb\":-1,\"ParallelDownloadsPerFile\":16,\"WriteBufferSize\":4194304},\"FileSystem\":{\"DirMode\":\"755\",\"DisableParallelDirops\":false,\"ExperimentalEnableDentryCache\":false,\"ExperimentalEnableReaddirplus\":false,\"FileMode\":\"644\",\"FuseOptions\":[],\"Gid\":-1,\"IgnoreInterrupts\":true,\"KernelListCacheTtlSecs\":0,\"PreconditionErrors\":true,\"RenameDirLimit\":0,\"TempDir\":\"\",\"Uid\":-1},\"Foreground\":false,\"GcsAuth\":{\"AnonymousAccess\":false,\"KeyFile\":\"\",\"ReuseTokenFromUrl\":true,\"TokenUrl\":\"\"},\"GcsConnection\":{\"BillingProject\":\"\",\"ClientProtocol\":\"http1\",\"CustomEndpoint\":\"\",\"ExperimentalEnableJsonRead\":false,\"GrpcConnPoolSize\":1,\"HttpClientTimeout\":0,\"LimitBytesPerSec\":-1,\"LimitOpsPerSec\":-1,\"MaxConnsPerHost\":0,\"MaxIdleConnsPerHost\":100,\"SequentialReadSizeMb\":200},\"GcsRetries\":{\"ChunkTransferTimeoutSecs\":10,\"MaxRetryAttempts\":0,\"MaxRetrySleep\":30000000000,\"Multiplier\":2,\"ReadStall\":{\"Enable\":true,\"InitialReqTimeout\":20000000000,\"MaxReqTimeout\":1200000000000,\"MinReqTimeout\":1500000000,\"ReqIncreaseRate\":15,\"ReqTargetPercentile\":0.99}},\"ImplicitDirs\":false,\"List\":{\"EnableEmptyManagedFolders\":false},\"Logging\":{\"FilePath\":\"\",\"Format\":\"json\",\"LogRotate\":{\"BackupFileCount\":10,\"Compress\":true,\"MaxFileSizeMb\":512},\"Severity\":\"INFO\"},\"MachineType\":\"\",\"MetadataCache\":{\"DeprecatedStatCacheCapacity\":20460,\"DeprecatedStatCacheTtl\":60000000000,\"DeprecatedTypeCacheTtl\":60000000000,\"EnableNonexistentTypeCache\":false,\"ExperimentalMetadataPrefetchOnMount\":\"disabled\",\"NegativeTtlSecs\":5,\"StatCacheMaxSizeMb\":33,\"TtlSecs\":60,\"TypeCacheMaxSizeMb\":4},\"Metrics\":{\"CloudMetricsExportIntervalSecs\":0,\"PrometheusPort\":0,\"StackdriverExportInterval\":0,\"UseNewNames\":false},\"Monitoring\":{\"ExperimentalTracingMode\":\"\",\"ExperimentalTracingSamplingRatio\":0},\"OnlyDir\":\"\",\"Profiling\":{\"AllocatedHeap\":true,\"Cpu\":true,\"Enabled\":false,\"Goroutines\":false,\"Heap\":true,\"Label\":\"gcsfuse-0.0.0\",\"Mutex\":false},\"Read\":{\"InactiveStreamTimeout\":10000000000},\"Write\":{\"BlockSizeMb\":33554432,\"CreateEmptyFile\":false,\"EnableStreamingWrites\":true,\"ExperimentalEnableRapidAppends\":false,\"GlobalMaxBlocks\":4,\"MaxBlocksPerFile\":1}}}\n",
      "{\"timestamp\":{\"seconds\":1752536718,\"nanos\":656537149},\"severity\":\"INFO\",\"message\":\"File system has been successfully mounted.\"}\n"
     ]
    }
   ],
   "source": [
    "!gcsfuse forecasting_customer_product /home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833d61d-d76f-430c-b52d-6a4ba7c05224",
   "metadata": {},
   "source": [
    "# ✅ 1) Cálculo y aplicación de la estandarización\n",
    "\n",
    "### 👉 Idea clave:\n",
    "\n",
    "- Calculas media y desvío por product_id usando solo los registros de entrenamiento (train_set).\n",
    "- Creas un scaler_dict para mapear cada product_id a su (mean, std).\n",
    "- Normalizas tn y clase solo en training.\n",
    "- En test, aplicas el mismo scaler_dict para transformar los features antes de predecir y reviertes la predicción después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "670c745a-acfb-4d86-9e9b-163ced318b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos cargados: (12138186, 194)\n",
      "✅ Diccionario de escalado cargado: 780 productos\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1) Cargar parquet escalado + scaler_dict\n",
    "# -------------------------------\n",
    "df_scaled = pd.read_parquet(\"panel_cliente_producto_fe_scaled.parquet\")\n",
    "\n",
    "with open(\"scaler_dict.pkl\", 'rb') as f:\n",
    "    scaler_dict = pickle.load(f)\n",
    "\n",
    "print(f\"✅ Datos cargados: {df_scaled.shape}\")\n",
    "print(f\"✅ Diccionario de escalado cargado: {len(scaler_dict)} productos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c2c8a4b-cef1-43bc-b2a2-49952942a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10297990, 195) | Test shape: (333840, 194)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2) Separar train/test\n",
    "# -------------------------------\n",
    "train_set = df_scaled[(df_scaled['fecha'] <= '2019-10-01') & df_scaled['clase'].notnull()].copy()\n",
    "test_set = df_scaled[df_scaled['fecha'] == '2019-12-01'].copy()\n",
    "\n",
    "# Crear sample_weight basado en tn_total\n",
    "\n",
    "train_set['sample_weight'] = train_set['tn']\n",
    "\n",
    "print(f\"Train shape: {train_set.shape} | Test shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de9a48a7-8b33-4cc5-801c-217629a02047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 191\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3) Features finales\n",
    "# -------------------------------\n",
    "features = [col for col in df_scaled.columns if col not in [\n",
    "    'periodo', 'fecha', 'clase'\n",
    "]]\n",
    "\n",
    "print(f\"Total features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10349c17-76a9-4d45-bcef-ba6d6b007c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"gcs_model_dir_fullpower_escalando\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.237-1 (2025-05-19)\n",
      "CPU Count:          48\n",
      "Memory Avail:       259.39 GB / 377.89 GB (68.6%)\n",
      "Disk Space Avail:   1048576.00 GB / 1048576.00 GB (100.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=4, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 3600s of the 14400s of remaining time (25%).\n",
      "\t\tContext path: \"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L2      -0.150645  -0.149435  mean_absolute_error       34.163231      63.164590  1224.522819                18.492778               36.819197         651.046959            2       True          3\n",
      "1  WeightedEnsemble_L3      -0.150645  -0.149435  mean_absolute_error       34.286280      63.405265  1224.910936                 0.123049                0.240674           0.388117            3       True          4\n",
      "2  WeightedEnsemble_L6      -0.150776  -0.149296  mean_absolute_error       49.823596      88.445937  1774.329509                 0.129308                0.229843           1.868810            6       True         10\n",
      "3    LightGBMXT_BAG_L3      -0.151180  -0.149923  mean_absolute_error       49.694288      88.216094  1772.460699                15.531058               25.051503         547.937880            3       True          5\n",
      "4  WeightedEnsemble_L4      -0.151180  -0.149923  mean_absolute_error       49.852506      88.453906  1772.840369                 0.158218                0.237813           0.379670            4       True          6\n",
      "5    LightGBMXT_BAG_L1      -0.151689  -0.150229  mean_absolute_error       15.670453      26.345393   573.475860                15.670453               26.345393         573.475860            1       True          1\n",
      "6  WeightedEnsemble_L2      -0.151689  -0.150229  mean_absolute_error       15.767809      26.581004   573.834750                 0.097356                0.235612           0.358890            2       True          2\n",
      "7    LightGBMXT_BAG_L4      -0.152386  -0.151034  mean_absolute_error       60.412867     103.915346  2171.556479                10.718579               15.699252         399.095779            4       True          7\n",
      "8  WeightedEnsemble_L5      -0.152386  -0.151034  mean_absolute_error       60.601361     104.139559  2171.919346                 0.188493                0.224213           0.362867            5       True          8\n",
      "9    LightGBMXT_BAG_L5      -0.268084  -0.264887  mean_absolute_error       65.536159     110.612383  2314.407898                 5.123292                6.697038         142.851419            5       True          9\n",
      "\t4\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t4036s\t = DyStack   runtime |\t10364s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=4.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=4)`\n",
      "Beginning AutoGluon training ... Time limit = 10364s\n",
      "AutoGluon will save models to \"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_escalando\"\n",
      "Train Data Rows:    10297990\n",
      "Train Data Columns: 191\n",
      "Label Column:       clase\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    256756.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17399.08 MB (6.8% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 6.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 12): ['tn_34', 'diff_tn_34', 'tn_35', 'diff_tn_35', 'tn_36', 'diff_tn_36', 'rollmean_34', 'diff_rollmean_34', 'rollmean_35', 'diff_rollmean_35', 'rollmean_36', 'diff_rollmean_36']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['rollmean_1', 'diff_rollmean_1']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 2 | ['rollmean_1', 'diff_rollmean_1']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 148 | ['tn', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\t\t('int', [])    :  24 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\t\t('object', []) :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\t\t('float', [])     : 148 | ['tn', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\t\t('int', [])       :  18 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\t\t('int', ['bool']) :   6 | ['is_min_3', 'is_max_3', 'is_min_6', 'is_max_6', 'is_min_12', ...]\n",
      "\t142.2s = Fit runtime\n",
      "\t177 features in original data used to generate 177 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13002.91 MB (5.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 164.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2719.00s of the 10198.78s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 59035.68s compared to 3435.28s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2621.36s of the 10101.14s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 60602.72s compared to 3308.27s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2523.64s of the 10003.42s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 34.99% memory usage per fold, 69.98%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=24, gpus=0, memory=34.99%)\n",
      "\t-0.1466\t = Validation score   (-mean_absolute_error)\n",
      "\t2077.84s\t = Training   runtime\n",
      "\t176.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 346.35s of the 7826.13s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 34.04% memory usage per fold, 68.07%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=24, gpus=0, memory=34.04%)\n",
      "\t-0.1539\t = Validation score   (-mean_absolute_error)\n",
      "\t277.43s\t = Training   runtime\n",
      "\t13.9s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 16.37s of the 7496.15s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -4.3s)\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 7412.03s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t-0.1466\t = Validation score   (-mean_absolute_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2468.51s of the 7401.60s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 36.21% memory usage per fold, 72.43%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=24, gpus=0, memory=36.21%)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4) Entrenar Autogluon Tabular\n",
    "# -------------------------------\n",
    "predictor = TabularPredictor(\n",
    "    label='clase',\n",
    "    problem_type='regression',\n",
    "    eval_metric='mae',\n",
    "    path='gcs_model_dir_fullpower_escalando'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_set[features + ['clase']],\n",
    "    time_limit=14400,\n",
    "     ag_args_fit={'sample_weight': 'sample_weight'},\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=5,\n",
    "    num_stack_levels=4\n",
    ")\n",
    "\n",
    "print(\"✅ Entrenamiento finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9dad4-b2ea-48b8-ac30-6497e52de803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5) Predicciones\n",
    "# -------------------------------\n",
    "test_set['clase_pred_scaled'] = predictor.predict(test_set[features])\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Inversa de escalado\n",
    "# -------------------------------\n",
    "def inverse_scale(row):\n",
    "    pid = row['product_id']\n",
    "    if pid in scaler_dict:\n",
    "        m = scaler_dict[pid]['mean']\n",
    "        s = scaler_dict[pid]['std']\n",
    "        return (row['clase_pred_scaled'] * s) + m\n",
    "    else:\n",
    "        return row['clase_pred_scaled']\n",
    "\n",
    "test_set['tn_pred'] = test_set.apply(inverse_scale, axis=1)\n",
    "test_set['tn_pred'] = test_set['tn_pred'].clip(lower=0)\n",
    "\n",
    "# -------------------------------\n",
    "# 7) Agregar por producto\n",
    "# -------------------------------\n",
    "df_final = (\n",
    "    test_set.groupby('product_id', as_index=False)['tn_pred']\n",
    "    .sum()\n",
    "    .rename(columns={'tn_pred': 'tn'})\n",
    ")\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 8) Exportar CSV final\n",
    "# -------------------------------\n",
    "df_final.to_csv('forecast_final_desescalado.csv', index=False)\n",
    "\n",
    "print(\"✅ Forecast final generado: forecast_final_desescalado.csv\")\n",
    "print(f\"Productos únicos: {df_final['product_id'].nunique()}\")\n",
    "print(f\"Total TN predichas: {df_final['tn'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3f204-f136-4fd1-bdca-9daecd1101ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 9) Leaderboard (performance interna)\n",
    "# -------------------------------\n",
    "print(\"\\n🔍 Leaderboard:\")\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "print(lb)\n",
    "\n",
    "# -------------------------------\n",
    "# 10) Importancia de features\n",
    "# -------------------------------\n",
    "print(\"\\n🔍 Importancia de Features:\")\n",
    "fi = predictor.feature_importance(train_set[features + ['clase']])\n",
    "fi = fi.reset_index().rename(columns={'index': 'feature'})\n",
    "print(fi.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216cb53-88e8-4550-ad55-655ba921c833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
