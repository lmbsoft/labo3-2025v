{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfd9ae5-edee-452b-929f-d13eecb983d2",
   "metadata": {},
   "source": [
    "# Modelado tabular con Autgluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba6e856-5142-4c55-9453-e7cd9cb05c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease [1477 B]\n",
      "Hit:2 https://deb.debian.org/debian bullseye InRelease                         \n",
      "Hit:3 https://download.docker.com/linux/debian bullseye InRelease   \n",
      "Get:4 https://deb.debian.org/debian-security bullseye-security InRelease [27.2 kB]\n",
      "Get:5 https://deb.debian.org/debian bullseye-updates InRelease [44.0 kB]\n",
      "Get:6 https://deb.debian.org/debian bullseye-backports InRelease [48.9 kB]\n",
      "Hit:7 https://packages.cloud.google.com/apt gcsfuse-bullseye InRelease\n",
      "Hit:8 https://packages.cloud.google.com/apt google-compute-engine-bullseye-stable InRelease\n",
      "Hit:9 https://packages.cloud.google.com/apt cloud-sdk-bullseye InRelease\n",
      "Get:10 https://deb.debian.org/debian-security bullseye-security/main Sources [247 kB]\n",
      "Get:11 https://deb.debian.org/debian-security bullseye-security/main amd64 Packages [384 kB]\n",
      "Get:12 https://deb.debian.org/debian-security bullseye-security/main Translation-en [255 kB]\n",
      "Hit:13 https://packages.cloud.google.com/apt google-fast-socket InRelease      \n",
      "Fetched 1007 kB in 1s (1243 kB/s)               \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "gcsfuse is already the newest version (3.1.0).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install gcsfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafae9d5-f167-4844-a54d-837399e5957d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install autogluon.timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714f161-c384-4582-9df4-b2e170562023",
   "metadata": {},
   "source": [
    "# Carga librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34db802-71e7-4536-8484-73281601d474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80944f5-a7ef-4f3f-a194-ca859daa6053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddf2a47-869b-4059-ab6a-93745c17b19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!fusermount -u /home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top100_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165665a4-ea68-48fa-ae69-2dc8e0cd0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":{\"seconds\":1752969862,\"nanos\":656759083},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/3.1.0 (Go version go1.24.0) for app \\\"\\\" using mount point: /home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3\\n\"}\n",
      "{\"timestamp\":{\"seconds\":1752969862,\"nanos\":656812859},\"severity\":\"INFO\",\"message\":\"GCSFuse config\",\"config\":{\"AppName\":\"\",\"CacheDir\":\"\",\"Debug\":{\"ExitOnInvariantViolation\":false,\"Fuse\":false,\"Gcs\":false,\"LogMutex\":false},\"DisableAutoconfig\":false,\"EnableAtomicRenameObject\":true,\"EnableGoogleLibAuth\":false,\"EnableHns\":true,\"EnableNewReader\":false,\"FileCache\":{\"CacheFileForRangeRead\":false,\"DownloadChunkSizeMb\":200,\"EnableCrc\":false,\"EnableODirect\":false,\"EnableParallelDownloads\":false,\"ExperimentalExcludeRegex\":\"\",\"ExperimentalParallelDownloadsDefaultOn\":true,\"MaxParallelDownloads\":96,\"MaxSizeMb\":-1,\"ParallelDownloadsPerFile\":16,\"WriteBufferSize\":4194304},\"FileSystem\":{\"DirMode\":\"755\",\"DisableParallelDirops\":false,\"ExperimentalEnableDentryCache\":false,\"ExperimentalEnableReaddirplus\":false,\"FileMode\":\"644\",\"FuseOptions\":[],\"Gid\":-1,\"IgnoreInterrupts\":true,\"KernelListCacheTtlSecs\":0,\"PreconditionErrors\":true,\"RenameDirLimit\":0,\"TempDir\":\"\",\"Uid\":-1},\"Foreground\":false,\"GcsAuth\":{\"AnonymousAccess\":false,\"KeyFile\":\"\",\"ReuseTokenFromUrl\":true,\"TokenUrl\":\"\"},\"GcsConnection\":{\"BillingProject\":\"\",\"ClientProtocol\":\"http1\",\"CustomEndpoint\":\"\",\"ExperimentalEnableJsonRead\":false,\"GrpcConnPoolSize\":1,\"HttpClientTimeout\":0,\"LimitBytesPerSec\":-1,\"LimitOpsPerSec\":-1,\"MaxConnsPerHost\":0,\"MaxIdleConnsPerHost\":100,\"SequentialReadSizeMb\":200},\"GcsRetries\":{\"ChunkTransferTimeoutSecs\":10,\"MaxRetryAttempts\":0,\"MaxRetrySleep\":30000000000,\"Multiplier\":2,\"ReadStall\":{\"Enable\":true,\"InitialReqTimeout\":20000000000,\"MaxReqTimeout\":1200000000000,\"MinReqTimeout\":1500000000,\"ReqIncreaseRate\":15,\"ReqTargetPercentile\":0.99}},\"ImplicitDirs\":false,\"List\":{\"EnableEmptyManagedFolders\":false},\"Logging\":{\"FilePath\":\"\",\"Format\":\"json\",\"LogRotate\":{\"BackupFileCount\":10,\"Compress\":true,\"MaxFileSizeMb\":512},\"Severity\":\"INFO\"},\"MachineType\":\"\",\"MetadataCache\":{\"DeprecatedStatCacheCapacity\":20460,\"DeprecatedStatCacheTtl\":60000000000,\"DeprecatedTypeCacheTtl\":60000000000,\"EnableNonexistentTypeCache\":false,\"ExperimentalMetadataPrefetchOnMount\":\"disabled\",\"NegativeTtlSecs\":5,\"StatCacheMaxSizeMb\":33,\"TtlSecs\":60,\"TypeCacheMaxSizeMb\":4},\"Metrics\":{\"CloudMetricsExportIntervalSecs\":0,\"PrometheusPort\":0,\"StackdriverExportInterval\":0,\"UseNewNames\":false},\"Monitoring\":{\"ExperimentalTracingMode\":\"\",\"ExperimentalTracingSamplingRatio\":0},\"OnlyDir\":\"\",\"Profiling\":{\"AllocatedHeap\":true,\"Cpu\":true,\"Enabled\":false,\"Goroutines\":false,\"Heap\":true,\"Label\":\"gcsfuse-0.0.0\",\"Mutex\":false},\"Read\":{\"InactiveStreamTimeout\":10000000000},\"Write\":{\"BlockSizeMb\":33554432,\"CreateEmptyFile\":false,\"EnableStreamingWrites\":true,\"ExperimentalEnableRapidAppends\":false,\"GlobalMaxBlocks\":4,\"MaxBlocksPerFile\":1}}}\n",
      "{\"timestamp\":{\"seconds\":1752969862,\"nanos\":776984452},\"severity\":\"INFO\",\"message\":\"File system has been successfully mounted.\"}\n"
     ]
    }
   ],
   "source": [
    "!gcsfuse forecasting_customer_product /home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670c745a-acfb-4d86-9e9b-163ced318b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV Prophet cargado. Shape: (7249573, 9)\n",
      "âœ… Merge completado. Shape final: (12138186, 200)\n",
      "âœ… ConversiÃ³n de float64 a float32 completada para columnas: ['tn_x', 'inflacion', 'cambio_dolar', 'stock_final', 'clase', 'tn_1', 'diff_tn_1', 'tn_2', 'diff_tn_2', 'tn_3', 'diff_tn_3', 'tn_4', 'diff_tn_4', 'tn_5', 'diff_tn_5', 'tn_6', 'diff_tn_6', 'tn_7', 'diff_tn_7', 'tn_8', 'diff_tn_8', 'tn_9', 'diff_tn_9', 'tn_10', 'diff_tn_10', 'tn_11', 'diff_tn_11', 'tn_12', 'diff_tn_12', 'tn_13', 'diff_tn_13', 'tn_14', 'diff_tn_14', 'tn_15', 'diff_tn_15', 'tn_16', 'diff_tn_16', 'tn_17', 'diff_tn_17', 'tn_18', 'diff_tn_18', 'tn_19', 'diff_tn_19', 'tn_20', 'diff_tn_20', 'tn_21', 'diff_tn_21', 'tn_22', 'diff_tn_22', 'tn_23', 'diff_tn_23', 'tn_24', 'diff_tn_24', 'tn_25', 'diff_tn_25', 'tn_26', 'diff_tn_26', 'tn_27', 'diff_tn_27', 'tn_28', 'diff_tn_28', 'tn_29', 'diff_tn_29', 'tn_30', 'diff_tn_30', 'tn_31', 'diff_tn_31', 'tn_32', 'diff_tn_32', 'tn_33', 'diff_tn_33', 'tn_34', 'diff_tn_34', 'tn_35', 'diff_tn_35', 'tn_36', 'diff_tn_36', 'rollmean_1', 'diff_rollmean_1', 'rollmean_2', 'diff_rollmean_2', 'rollmean_3', 'diff_rollmean_3', 'rollmean_4', 'diff_rollmean_4', 'rollmean_5', 'diff_rollmean_5', 'rollmean_6', 'diff_rollmean_6', 'rollmean_7', 'diff_rollmean_7', 'rollmean_8', 'diff_rollmean_8', 'rollmean_9', 'diff_rollmean_9', 'rollmean_10', 'diff_rollmean_10', 'rollmean_11', 'diff_rollmean_11', 'rollmean_12', 'diff_rollmean_12', 'rollmean_13', 'diff_rollmean_13', 'rollmean_14', 'diff_rollmean_14', 'rollmean_15', 'diff_rollmean_15', 'rollmean_16', 'diff_rollmean_16', 'rollmean_17', 'diff_rollmean_17', 'rollmean_18', 'diff_rollmean_18', 'rollmean_19', 'diff_rollmean_19', 'rollmean_20', 'diff_rollmean_20', 'rollmean_21', 'diff_rollmean_21', 'rollmean_22', 'diff_rollmean_22', 'rollmean_23', 'diff_rollmean_23', 'rollmean_24', 'diff_rollmean_24', 'rollmean_25', 'diff_rollmean_25', 'rollmean_26', 'diff_rollmean_26', 'rollmean_27', 'diff_rollmean_27', 'rollmean_28', 'diff_rollmean_28', 'rollmean_29', 'diff_rollmean_29', 'rollmean_30', 'diff_rollmean_30', 'rollmean_31', 'diff_rollmean_31', 'rollmean_32', 'diff_rollmean_32', 'rollmean_33', 'diff_rollmean_33', 'rollmean_34', 'diff_rollmean_34', 'rollmean_35', 'diff_rollmean_35', 'rollmean_36', 'diff_rollmean_36', 'month_sin', 'month_cos', 'pct_change_1', 'rolling_std_3', 'brand_avg', 'ratio_to_brand_avg', 'cat1_avg', 'ratio_to_cat1_avg', 'cat2_avg', 'ratio_to_cat2_avg', 'cat3_avg', 'ratio_to_cat3_avg', 'product_target_enc', 'customer_target_enc', 'tn_y', 'trend', 'seasonal', 'additive_terms', 'residual', 'slope_trend_3']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12138186 entries, 0 to 12138185\n",
      "Columns: 200 entries, customer_id to slope_trend_3\n",
      "dtypes: datetime64[ns](1), float32(169), int32(10), int64(14), object(6)\n",
      "memory usage: 10.0+ GB\n",
      "None\n",
      "âœ… Merge completado. Shape final: (12138186, 200)\n",
      "âœ… Parquet cargado. Shape: (12138186, 200)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# 1) Cargar parquet con FE\n",
    "# ------------------------\n",
    "\n",
    "parquet_path = \"panel_cliente_producto_fe.parquet\"\n",
    "df_modelo = pd.read_parquet(parquet_path)\n",
    "\n",
    "# ------------------------\n",
    "# 2) Cargar Prophet features\n",
    "# ------------------------\n",
    "csv_path = \"prophet_features_customer_product.csv\"\n",
    "df_prophet = pd.read_csv(csv_path)\n",
    "print(f\"âœ… CSV Prophet cargado. Shape: {df_prophet.shape}\")\n",
    "\n",
    "# ------------------------\n",
    "# 3) Asegurar consistencia de tipos\n",
    "# ------------------------\n",
    "df_modelo['fecha'] = pd.to_datetime(df_modelo['fecha'])\n",
    "df_prophet['fecha'] = pd.to_datetime(df_prophet['fecha'])\n",
    "\n",
    "# ------------------------\n",
    "# 4) Realizar join por 'product_id' y 'fecha'\n",
    "# ------------------------\n",
    "df_modelo_final = df_modelo.merge(\n",
    "    df_prophet,\n",
    "    on=['customer_id','product_id', 'fecha'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"âœ… Merge completado. Shape final: {df_modelo_final.shape}\")\n",
    "\n",
    "# ------------------------\n",
    "# 5) Convertir columnas float64 a float32 para ahorrar memoria\n",
    "# ------------------------\n",
    "float64_cols = df_modelo_final.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "df_modelo_final[float64_cols] = df_modelo_final[float64_cols].astype('float32')\n",
    "\n",
    "print(f\"âœ… ConversiÃ³n de float64 a float32 completada para columnas: {float64_cols}\")\n",
    "print(df_modelo_final.info())\n",
    "\n",
    "print(f\"âœ… Merge completado. Shape final: {df_modelo_final.shape}\")\n",
    "\n",
    "# Verifica el resultado\n",
    "df_modelo_final.head()\n",
    "\n",
    "\n",
    "print(f\"âœ… Parquet cargado. Shape: {df_modelo_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1b5eb9-c2c2-48e9-9c0d-60b8815f4319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 40 clientes:\n",
      "[10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10016, 10015, 10017, 10018, 10019, 10020, 10023, 10022, 10021, 10024, 10025, 10039, 10026, 10028, 10030, 10033, 10027, 10034, 10032, 10031, 10038, 10035, 10037, 10036, 10042, 10041, 10082, 10029, 10045, 10044, 10043, 10040, 10047, 10046, 10074, 10051, 10048, 10050, 10057, 10049, 10053, 10055, 10054, 10127, 10052, 10060, 10056, 10064, 10061, 10062, 10059, 10063, 10058, 10066, 10065, 10067, 10069, 10072, 10071, 10068, 10076, 10073, 10070, 10075, 10081, 10080, 10084, 10086, 10088, 10077, 10078, 10090, 10089, 10079, 10091, 10083, 10085, 10097, 10096, 10087, 10094, 10092, 10093, 10101, 10099, 10098, 10095, 10102, 10104, 10105, 10109, 10113, 10103, 10107, 10108, 10110, 10112, 10106, 10136, 10111, 10115, 10118, 10117, 10121, 10100, 10114, 10116, 10130, 10119, 10122, 10125]\n",
      "TOP40 shape: (2763524, 200) | Otros shape: (9374662, 200)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ðŸ“¦ BLOQUE 1 â€” Filtrar TOP 70 clientes y resto\n",
    "# =============================================\n",
    "\n",
    "# 2) Calcular compra promedio por cliente\n",
    "cliente_avg = (\n",
    "    df_modelo_final.groupby('customer_id')['tn_x']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tn_x': 'avg_tn'})\n",
    "    .sort_values('avg_tn', ascending=False)\n",
    ")\n",
    "\n",
    "# 3) Identificar TOP 20 clientes\n",
    "top_40_customers = cliente_avg.head(125)['customer_id'].tolist()\n",
    "print(f\"TOP 40 clientes:\\n{top_40_customers}\")\n",
    "\n",
    "# 4) Crear datasets\n",
    "df_top40 = df_modelo_final[df_modelo_final['customer_id'].isin(top_40_customers)].copy()\n",
    "df_otros = df_modelo_final[~df_modelo_final['customer_id'].isin(top_40_customers)].copy()\n",
    "\n",
    "print(f\"TOP40 shape: {df_top40.shape} | Otros shape: {df_otros.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ade4f-4930-476e-b4f8-cfaade2aa35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"gcs_model_dir_fullpower_hibrido_top125_v3\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.237-1 (2025-05-19)\n",
      "CPU Count:          48\n",
      "Memory Avail:       269.68 GB / 377.89 GB (71.4%)\n",
      "Disk Space Avail:   1048576.00 GB / 1048576.00 GB (100.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-07-20 00:06:52,383\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Beginning AutoGluon training ... Time limit = 8097s\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m AutoGluon will save models to \"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Train Data Rows:    2269174\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Train Data Columns: 196\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Label Column:       clase\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tAvailable Memory:                    270215.96 MB\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTrain Data (Original)  Memory Usage: 2482.08 MB (0.9% of available memory)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tUseless Original Features (Count: 12): ['tn_34', 'diff_tn_34', 'tn_35', 'diff_tn_35', 'tn_36', 'diff_tn_36', 'rollmean_34', 'diff_rollmean_34', 'rollmean_35', 'diff_rollmean_35', 'rollmean_36', 'diff_rollmean_36']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tUnused Original Features (Count: 2): ['rollmean_1', 'diff_rollmean_1']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('float', []) : 2 | ['rollmean_1', 'diff_rollmean_1']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('datetime', []) :   1 | ['fecha']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('float', [])    : 152 | ['tn_x', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('int', [])      :  24 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('object', [])   :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('category', [])             :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('float', [])                : 152 | ['tn_x', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('int', [])                  :  18 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('int', ['bool'])            :   6 | ['is_min_3', 'is_max_3', 'is_min_6', 'is_max_6', 'is_min_12', ...]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t('int', ['datetime_as_int']) :   1 | ['fecha']\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t29.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t182 features in original data used to generate 182 features in processed data.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTrain Data (Processed) Memory Usage: 1636.03 MB (0.6% of available memory)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Data preprocessing and feature engineering runtime = 32.77s ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5374.94s of the 8064.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 109, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model = self._fit_with_samples(X=X, y=y, model_params=params, time_limit=time_limit - (time.time() - time_start))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 240, in _fit_with_samples\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model = model_type(**model_params).fit(X_samp, y_samp)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_regression.py\", line 222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self._fit(X, y)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_base.py\", line 478, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, y = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = check_array(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5358.74s of the 8048.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 109, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model = self._fit_with_samples(X=X, y=y, model_params=params, time_limit=time_limit - (time.time() - time_start))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 240, in _fit_with_samples\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model = model_type(**model_params).fit(X_samp, y_samp)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_regression.py\", line 222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self._fit(X, y)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_base.py\", line 478, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, y = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = check_array(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5344.05s of the 8033.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=3.91%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [1000]\tvalid_set's l1: 0.280147\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [1000]\tvalid_set's l1: 0.280777\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [1000]\tvalid_set's l1: 0.279575\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [2000]\tvalid_set's l1: 0.284572\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [2000]\tvalid_set's l1: 0.276846\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [2000]\tvalid_set's l1: 0.279054\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [2000]\tvalid_set's l1: 0.274577\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [2000]\tvalid_set's l1: 0.277759\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [3000]\tvalid_set's l1: 0.282753\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [3000]\tvalid_set's l1: 0.275253\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [3000]\tvalid_set's l1: 0.277393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [3000]\tvalid_set's l1: 0.280671\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [3000]\tvalid_set's l1: 0.272941\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [3000]\tvalid_set's l1: 0.276712\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [4000]\tvalid_set's l1: 0.281419\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [4000]\tvalid_set's l1: 0.274316\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [4000]\tvalid_set's l1: 0.276057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [4000]\tvalid_set's l1: 0.271842\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [4000]\tvalid_set's l1: 0.279658\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [4000]\tvalid_set's l1: 0.274774\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [4000]\tvalid_set's l1: 0.275725\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [5000]\tvalid_set's l1: 0.273403\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [5000]\tvalid_set's l1: 0.280502\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [5000]\tvalid_set's l1: 0.275308\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [5000]\tvalid_set's l1: 0.27119\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [5000]\tvalid_set's l1: 0.278646\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [5000]\tvalid_set's l1: 0.275026\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [5000]\tvalid_set's l1: 0.273753\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [6000]\tvalid_set's l1: 0.272615\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [6000]\tvalid_set's l1: 0.279717\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [6000]\tvalid_set's l1: 0.274564\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [6000]\tvalid_set's l1: 0.277825\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [6000]\tvalid_set's l1: 0.270673\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [6000]\tvalid_set's l1: 0.274459\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [6000]\tvalid_set's l1: 0.272904\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [7000]\tvalid_set's l1: 0.2791\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [7000]\tvalid_set's l1: 0.272056\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [7000]\tvalid_set's l1: 0.274081\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [7000]\tvalid_set's l1: 0.277038\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [7000]\tvalid_set's l1: 0.270025\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [7000]\tvalid_set's l1: 0.272364\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [8000]\tvalid_set's l1: 0.278415\n",
      "\u001b[36m(_ray_fit pid=112502)\u001b[0m [8000]\tvalid_set's l1: 0.271602\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [8000]\tvalid_set's l1: 0.273561\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [8000]\tvalid_set's l1: 0.276476\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [8000]\tvalid_set's l1: 0.269553\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [8000]\tvalid_set's l1: 0.271819\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [9000]\tvalid_set's l1: 0.278116\n",
      "\u001b[36m(_ray_fit pid=112500)\u001b[0m [9000]\tvalid_set's l1: 0.272645\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [9000]\tvalid_set's l1: 0.273057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [9000]\tvalid_set's l1: 0.276067\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [9000]\tvalid_set's l1: 0.268975\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [9000]\tvalid_set's l1: 0.273006\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [9000]\tvalid_set's l1: 0.271399\n",
      "\u001b[36m(_ray_fit pid=112499)\u001b[0m [10000]\tvalid_set's l1: 0.277677\n",
      "\u001b[36m(_ray_fit pid=112500)\u001b[0m [10000]\tvalid_set's l1: 0.272231\n",
      "\u001b[36m(_ray_fit pid=112497)\u001b[0m [10000]\tvalid_set's l1: 0.27262\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=112503)\u001b[0m [10000]\tvalid_set's l1: 0.275657\n",
      "\u001b[36m(_ray_fit pid=112498)\u001b[0m [10000]\tvalid_set's l1: 0.268623\n",
      "\u001b[36m(_ray_fit pid=112501)\u001b[0m [10000]\tvalid_set's l1: 0.27274\n",
      "\u001b[36m(_ray_fit pid=112504)\u001b[0m [10000]\tvalid_set's l1: 0.271042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2727\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1684.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t694.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 3579.60s of the 6269.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=3.93%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [1000]\tvalid_set's l1: 0.278667\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [1000]\tvalid_set's l1: 0.279921\n",
      "\u001b[36m(_ray_fit pid=124528)\u001b[0m [1000]\tvalid_set's l1: 0.276359\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [2000]\tvalid_set's l1: 0.275105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124534)\u001b[0m [2000]\tvalid_set's l1: 0.280762\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124529)\u001b[0m [2000]\tvalid_set's l1: 0.281321\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [3000]\tvalid_set's l1: 0.272708\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124534)\u001b[0m [3000]\tvalid_set's l1: 0.278327\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [3000]\tvalid_set's l1: 0.274165\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [4000]\tvalid_set's l1: 0.271139\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124535)\u001b[0m [4000]\tvalid_set's l1: 0.271207\n",
      "\u001b[36m(_ray_fit pid=124534)\u001b[0m [4000]\tvalid_set's l1: 0.277002\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [4000]\tvalid_set's l1: 0.272699\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [5000]\tvalid_set's l1: 0.269972\n",
      "\u001b[36m(_ray_fit pid=124535)\u001b[0m [5000]\tvalid_set's l1: 0.270089\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [5000]\tvalid_set's l1: 0.271188\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [5000]\tvalid_set's l1: 0.27168\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [6000]\tvalid_set's l1: 0.269362\n",
      "\u001b[36m(_ray_fit pid=124535)\u001b[0m [6000]\tvalid_set's l1: 0.269445\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [6000]\tvalid_set's l1: 0.2705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [6000]\tvalid_set's l1: 0.271061\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [7000]\tvalid_set's l1: 0.268629\n",
      "\u001b[36m(_ray_fit pid=124528)\u001b[0m [7000]\tvalid_set's l1: 0.266641\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [7000]\tvalid_set's l1: 0.269871\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [7000]\tvalid_set's l1: 0.270436\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [8000]\tvalid_set's l1: 0.268078\n",
      "\u001b[36m(_ray_fit pid=124534)\u001b[0m [8000]\tvalid_set's l1: 0.27418\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [8000]\tvalid_set's l1: 0.269371\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [8000]\tvalid_set's l1: 0.269935\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [9000]\tvalid_set's l1: 0.267647\n",
      "\u001b[36m(_ray_fit pid=124528)\u001b[0m [9000]\tvalid_set's l1: 0.265479\n",
      "\u001b[36m(_ray_fit pid=124529)\u001b[0m [9000]\tvalid_set's l1: 0.273869\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [9000]\tvalid_set's l1: 0.269608\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124532)\u001b[0m [10000]\tvalid_set's l1: 0.267244\n",
      "\u001b[36m(_ray_fit pid=124528)\u001b[0m [10000]\tvalid_set's l1: 0.265131\n",
      "\u001b[36m(_ray_fit pid=124530)\u001b[0m [10000]\tvalid_set's l1: 0.268761\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=124533)\u001b[0m [10000]\tvalid_set's l1: 0.269225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2693\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1719.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t787.78s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1767.40s of the 4456.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused RandomForestMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X, y, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 375, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     estimator._compute_missing_values_in_feature_mask(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1750.76s of the 4440.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.13%)\n",
      "\u001b[36m(_ray_fit pid=136537)\u001b[0m \tRan out of time, early stopping on iteration 1462.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2837\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1393.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t2.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 341.72s of the 3031.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused ExtraTreesMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X, y, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 375, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     estimator._compute_missing_values_in_feature_mask(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_ray_fit pid=136540)\u001b[0m \tRan out of time, early stopping on iteration 1444.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 325.32s of the 3014.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=6.90%)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=148986, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=148986, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 230, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 141, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ImportError(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.3.1`.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 306.40s of the 2995.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=5.17%)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=149809, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 191, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix = create_dmatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return QuantileDMatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._init(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1680, in _init\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _check_call(ret)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m xgboost.core.XGBoostError: [01:33:26] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Stack trace:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (0) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a6ecc) [0x7f65ad112ecc]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (1) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5e9ec4) [0x7f65ad455ec4]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (2) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5ea949) [0x7f65ad456949]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (3) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x57b541) [0x7f65ad3e7541]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (4) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f65ad0253c8]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (5) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6d8a) [0x7f7ba7357d8a]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (6) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x61cd) [0x7f7ba73571cd]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (7) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xcd) [0x7f7ba735791d]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (8) /opt/conda/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x931f) [0x7f7ba709e31f]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ray.exceptions.RayTaskError(XGBoostError): \u001b[36mray::_ray_fit()\u001b[39m (pid=149809, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 191, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix = create_dmatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return QuantileDMatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._init(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1680, in _init\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _check_call(ret)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m xgboost.core.XGBoostError: [01:33:26] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Stack trace:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (0) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a6ecc) [0x7f65ad112ecc]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (1) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5e9ec4) [0x7f65ad455ec4]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (2) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5ea949) [0x7f65ad456949]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (3) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x57b541) [0x7f65ad3e7541]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (4) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f65ad0253c8]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (5) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6d8a) [0x7f7ba7357d8a]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (6) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x61cd) [0x7f7ba73571cd]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (7) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xcd) [0x7f7ba735791d]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (8) /opt/conda/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x931f) [0x7f7ba709e31f]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 249.22s of the 2938.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=3.77%)\n",
      "\u001b[36m(_ray_fit pid=150767)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
      "\u001b[36m(_ray_fit pid=150767)\u001b[0m   adjusted = values - mean\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=150767, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 759, in _process_train_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     df = self.processor.fit_transform(df)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     result = self._call_func_on_transformers(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super().__call__(iterable_with_config)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return output if self.return_generator else list(output)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 718, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     Xt = self._fit(X, y, routed_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, fitted_transformer = fit_transform_one_cached(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 918, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 434, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = self._validate_input(X, in_fit=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 363, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ve\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 344, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = check_array(X, input_name=\"X\", **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=150767, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 759, in _process_train_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     df = self.processor.fit_transform(df)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     result = self._call_func_on_transformers(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super().__call__(iterable_with_config)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return output if self.return_generator else list(output)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 718, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     Xt = self._fit(X, y, routed_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, fitted_transformer = fit_transform_one_cached(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 918, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 434, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = self._validate_input(X, in_fit=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 363, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ve\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 344, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = check_array(X, input_name=\"X\", **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 218.08s of the 2907.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=3.98%)\n",
      "\u001b[36m(_ray_fit pid=150768)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=150768)\u001b[0m   adjusted = values - mean\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=151715)\u001b[0m \tRan out of time, early stopping on iteration 643. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=151715)\u001b[0m \t[643]\tvalid_set's l1: 0.278138\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2778\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t168.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t40.17s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=151717)\u001b[0m \tRan out of time, early stopping on iteration 703. Best iteration is:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=151717)\u001b[0m \t[702]\tvalid_set's l1: 0.275412\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 29.47s of the 2718.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.13%)\n",
      "\u001b[36m(_ray_fit pid=152960)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.598\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t13.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1.16s of the 2690.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Model has no time left to train, skipping model... (Time Left = -4.0s)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "\u001b[36m(_ray_fit pid=152956)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 537.49s of the 2614.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.522, 'LightGBMXT_BAG_L1': 0.348, 'LightGBMLarge_BAG_L1': 0.13}\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2671\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2611.85s of the 2610.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.07%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=155112)\u001b[0m [1000]\tvalid_set's l1: 0.275888\n",
      "\u001b[36m(_ray_fit pid=155114)\u001b[0m [1000]\tvalid_set's l1: 0.278854\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=155111)\u001b[0m [1000]\tvalid_set's l1: 0.276705\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=155115)\u001b[0m [1000]\tvalid_set's l1: 0.26733\n",
      "\u001b[36m(_ray_fit pid=155109)\u001b[0m [1000]\tvalid_set's l1: 0.273621\n",
      "\u001b[36m(_ray_fit pid=155113)\u001b[0m [2000]\tvalid_set's l1: 0.266947\n",
      "\u001b[36m(_ray_fit pid=155112)\u001b[0m [2000]\tvalid_set's l1: 0.275188\n",
      "\u001b[36m(_ray_fit pid=155114)\u001b[0m [2000]\tvalid_set's l1: 0.278099\n",
      "\u001b[36m(_ray_fit pid=155110)\u001b[0m [2000]\tvalid_set's l1: 0.267928\n",
      "\u001b[36m(_ray_fit pid=155116)\u001b[0m [2000]\tvalid_set's l1: 0.27028\n",
      "\u001b[36m(_ray_fit pid=155111)\u001b[0m [2000]\tvalid_set's l1: 0.276549\n",
      "\u001b[36m(_ray_fit pid=155109)\u001b[0m [2000]\tvalid_set's l1: 0.273293\n",
      "\u001b[36m(_ray_fit pid=155115)\u001b[0m [2000]\tvalid_set's l1: 0.266886\n",
      "\u001b[36m(_ray_fit pid=155114)\u001b[0m [3000]\tvalid_set's l1: 0.277888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2717\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t479.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t50.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 2109.40s of the 2108.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.07%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=156963)\u001b[0m [1000]\tvalid_set's l1: 0.266791\n",
      "\u001b[36m(_ray_fit pid=156960)\u001b[0m [1000]\tvalid_set's l1: 0.262813\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2691\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t160.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t7.71s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1931.95s of the 1931.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused RandomForestMSE_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X, y, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 375, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     estimator._compute_missing_values_in_feature_mask(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1913.00s of the 1912.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.29%)\n",
      "\u001b[36m(_ray_fit pid=165944)\u001b[0m \tRan out of time, early stopping on iteration 1622.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2698\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t1522.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t3.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 373.28s of the 372.34s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=165943)\u001b[0m \tRan out of time, early stopping on iteration 1597.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused ExtraTreesMSE_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X, y, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 375, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     estimator._compute_missing_values_in_feature_mask(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 354.19s of the 353.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=7.17%)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=170896, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=170896, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 230, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 141, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ImportError(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.3.1`.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 333.13s of the 332.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=5.38%)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=171809, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 191, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix = create_dmatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return QuantileDMatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._init(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1680, in _init\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _check_call(ret)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m xgboost.core.XGBoostError: [02:17:53] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Stack trace:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (0) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a6ecc) [0x7f59f48f4ecc]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (1) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5e9ec4) [0x7f59f4c37ec4]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (2) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5ea949) [0x7f59f4c38949]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (3) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x57b541) [0x7f59f4bc9541]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (4) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f59f48073c8]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (5) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6d8a) [0x7f6ff1927d8a]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (6) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x61cd) [0x7f6ff19271cd]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (7) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xcd) [0x7f6ff192791d]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (8) /opt/conda/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x931f) [0x7f6ff166e31f]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ray.exceptions.RayTaskError(XGBoostError): \u001b[36mray::_ray_fit()\u001b[39m (pid=171809, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 191, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dmatrix = create_dmatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return QuantileDMatrix(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._init(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 1680, in _init\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _check_call(ret)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m xgboost.core.XGBoostError: [02:17:53] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Stack trace:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (0) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a6ecc) [0x7f59f48f4ecc]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (1) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5e9ec4) [0x7f59f4c37ec4]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (2) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x5ea949) [0x7f59f4c38949]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (3) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x57b541) [0x7f59f4bc9541]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (4) /opt/conda/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f59f48073c8]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (5) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6d8a) [0x7f6ff1927d8a]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (6) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(+0x61cd) [0x7f6ff19271cd]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (7) /opt/conda/lib/python3.10/lib-dynload/../../libffi.so.8(ffi_call+0xcd) [0x7f6ff192791d]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   [bt] (8) /opt/conda/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x931f) [0x7f6ff166e31f]\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 272.94s of the 271.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=3.89%)\n",
      "\u001b[36m(_ray_fit pid=172777)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
      "\u001b[36m(_ray_fit pid=172777)\u001b[0m   adjusted = values - mean\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=172777, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 759, in _process_train_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     df = self.processor.fit_transform(df)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     result = self._call_func_on_transformers(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super().__call__(iterable_with_config)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return output if self.return_generator else list(output)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 718, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     Xt = self._fit(X, y, routed_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, fitted_transformer = fit_transform_one_cached(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 918, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 434, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = self._validate_input(X, in_fit=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 363, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ve\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 344, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = check_array(X, input_name=\"X\", **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=172777, ip=10.70.80.80)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 759, in _process_train_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     df = self.processor.fit_transform(df)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     result = self._call_func_on_transformers(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return super().__call__(iterable_with_config)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return output if self.return_generator else list(output)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 718, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     Xt = self._fit(X, y, routed_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X, fitted_transformer = fit_transform_one_cached(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 918, in fit_transform\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 434, in fit\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = self._validate_input(X, in_fit=True)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 363, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ve\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 344, in _validate_input\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     X = validate_data(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     out = check_array(X, input_name=\"X\", **check_params)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     _assert_all_finite_element_wise(\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m     raise ValueError(msg_err)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 239.41s of the 238.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.11%)\n",
      "\u001b[36m(_ray_fit pid=172774)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=172774)\u001b[0m   adjusted = values - mean\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=173638)\u001b[0m [1000]\tvalid_set's l1: 0.263745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=173637)\u001b[0m \tRan out of time, early stopping on iteration 918. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=173637)\u001b[0m \t[788]\tvalid_set's l1: 0.273283\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2688\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t184.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t16.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 36.47s of the 35.52s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=173638)\u001b[0m \tRan out of time, early stopping on iteration 1007. Best iteration is:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=173638)\u001b[0m \t[905]\tvalid_set's l1: 0.26372\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.27%)\n",
      "\u001b[36m(_ray_fit pid=182709)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.5957\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t15.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t2.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -68.92s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=182708)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.333, 'LightGBMXT_BAG_L1': 0.19, 'LightGBMLarge_BAG_L2': 0.19, 'LightGBM_BAG_L2': 0.143, 'CatBoost_BAG_L2': 0.143}\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t-0.2655\t = Validation score   (-mean_absolute_error)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t2.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m AutoGluon training complete, total runtime = 8197.59s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 182.7 rows/s (283647 batch size)\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=108576)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L3      -0.266239  -0.265509  mean_absolute_error      167.184869    1552.646912  6849.294054                 0.129416                0.039167           2.316892            3       True         12\n",
      "1    WeightedEnsemble_L2      -0.267462  -0.267103  mean_absolute_error      146.885889    1522.030743  3573.517451                 0.118063                0.033371           1.290480            2       True          6\n",
      "2        LightGBM_BAG_L1      -0.267607  -0.269314  mean_absolute_error       70.280734     787.778579  1719.322320                70.280734              787.778579        1719.322320            1       True          2\n",
      "3   LightGBMLarge_BAG_L2      -0.268705  -0.268821  mean_absolute_error      158.944898    1541.322357  5163.575180                 7.725957               16.088628         184.108764            2       True         10\n",
      "4      LightGBMXT_BAG_L1      -0.269187  -0.272668  mean_absolute_error       66.185370     694.050875  1684.736466                66.185370              694.050875        1684.736466            1       True          1\n",
      "5      LightGBMXT_BAG_L2      -0.269459  -0.271748  mean_absolute_error      167.782336    1575.489234  5459.090052                16.563396               50.255505         479.623636            2       True          7\n",
      "6        LightGBM_BAG_L2      -0.269527  -0.269056  mean_absolute_error      156.651330    1532.947486  5140.027503                 5.432389                7.713757         160.561086            2       True          8\n",
      "7        CatBoost_BAG_L2      -0.269531  -0.269793  mean_absolute_error      153.897106    1528.805360  6502.307312                 2.678165                3.571631        1522.840896            2       True          9\n",
      "8   LightGBMLarge_BAG_L1      -0.280348  -0.277848  mean_absolute_error       10.301721      40.167918   168.168184                10.301721               40.167918         168.168184            1       True          4\n",
      "9        CatBoost_BAG_L1      -0.285471  -0.283657  mean_absolute_error        2.841276       2.091182  1393.930814                 2.841276                2.091182        1393.930814            1       True          3\n",
      "10  CatBoost_r177_BAG_L2      -0.597819  -0.595736  mean_absolute_error      152.912778    1527.453072  4994.785175                 1.693837                2.219342          15.318759            2       True         11\n",
      "11  CatBoost_r177_BAG_L1      -0.600101  -0.598050  mean_absolute_error        1.609839       1.145175    13.308632                 1.609839                1.145175          13.308632            1       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t8450s\t = DyStack   runtime |\t23950s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 23950s\n",
      "AutoGluon will save models to \"/home/jupyter/franco_maestria/gcs_model_dir_fullpower_hibrido_top125_v3\"\n",
      "Train Data Rows:    2552821\n",
      "Train Data Columns: 196\n",
      "Label Column:       clase\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    268960.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2794.03 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 12): ['tn_34', 'diff_tn_34', 'tn_35', 'diff_tn_35', 'tn_36', 'diff_tn_36', 'rollmean_34', 'diff_rollmean_34', 'rollmean_35', 'diff_rollmean_35', 'rollmean_36', 'diff_rollmean_36']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['rollmean_1', 'diff_rollmean_1']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 2 | ['rollmean_1', 'diff_rollmean_1']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :   1 | ['fecha']\n",
      "\t\t('float', [])    : 152 | ['tn_x', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\t\t('int', [])      :  24 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\t\t('object', [])   :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             :   5 | ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
      "\t\t('float', [])                : 152 | ['tn_x', 'inflacion', 'cambio_dolar', 'stock_final', 'tn_1', ...]\n",
      "\t\t('int', [])                  :  18 | ['customer_id', 'product_id', 'IPC', 'dias_feriados', 'sku_size', ...]\n",
      "\t\t('int', ['bool'])            :   6 | ['is_min_3', 'is_max_3', 'is_min_6', 'is_max_6', 'is_min_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :   1 | ['fecha']\n",
      "\t28.6s = Fit runtime\n",
      "\t182 features in original data used to generate 182 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1840.53 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 31.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 15941.86s of the 23918.75s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "    self._fit_single(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "    model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 109, in _fit\n",
      "    self.model = self._fit_with_samples(X=X, y=y, model_params=params, time_limit=time_limit - (time.time() - time_start))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 240, in _fit_with_samples\n",
      "    self.model = model_type(**model_params).fit(X_samp, y_samp)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_regression.py\", line 222, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 15925.16s of the 23902.06s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "    self._fit_single(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "    model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 109, in _fit\n",
      "    self.model = self._fit_with_samples(X=X, y=y, model_params=params, time_limit=time_limit - (time.time() - time_start))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 240, in _fit_with_samples\n",
      "    self.model = model_type(**model_params).fit(X_samp, y_samp)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_regression.py\", line 222, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/neighbors/_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 15911.18s of the 23888.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.42%)\n",
      "\t-0.2712\t = Validation score   (-mean_absolute_error)\n",
      "\t1729.88s\t = Training   runtime\n",
      "\t721.9s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 14101.22s of the 22078.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=6, gpus=0, memory=4.42%)\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# ðŸš€ BLOQUE 2 â€” Modelo TABULAR para TOP 40 clientes\n",
    "# ====================================================\n",
    "\n",
    "# âš™ï¸ Separar Train/Test\n",
    "df_top40['fecha'] = pd.to_datetime(df_top40['fecha'])\n",
    "train_top40 = df_top40[(df_top40['fecha'] <= '2019-10-01') & df_top40['clase'].notnull()].copy()\n",
    "test_top40 = df_top40[df_top40['fecha'] == '2019-12-01'].copy()\n",
    "\n",
    "# Escalar magnitud de toneladas vendidas\n",
    "train_top40['sample_weight'] = train_top40['tn_x']\n",
    "\n",
    "features_top40 = [col for col in df_top40.columns if col not in ['periodo', 'clase', 'tn_y','seasonal']]\n",
    "\n",
    "# âš™ï¸ Entrenar predictor\n",
    "predictor_top40 = TabularPredictor(label='clase', problem_type='regression', eval_metric='mae',\n",
    "    path='gcs_model_dir_fullpower_hibrido_top125_v3')\n",
    "predictor_top40.fit(\n",
    "    train_data=train_top40[features_top40 + ['clase']],\n",
    "    presets='best_quality',\n",
    "    time_limit=32400,\n",
    "    ag_args_fit={'sample_weight': 'sample_weight'}\n",
    ")\n",
    "\n",
    "# âš™ï¸ PredicciÃ³n y agregado por producto\n",
    "test_top40['tn_pred'] = predictor_top40.predict(test_top40[features_top40])\n",
    "df_top40_pred = (\n",
    "    test_top40.groupby('product_id')['tn_pred']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tn_pred': 'tn'})\n",
    ")\n",
    "print(df_top40_pred.head())\n",
    "\n",
    "# âš™ï¸ Guardar CSV parcial\n",
    "df_top40_pred.to_csv('forecast_top125_202002.csv', index=False)\n",
    "print(\"âœ… Forecast TOP100 guardado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d08055a-afd2-4696-8061-4ccdc969a725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Leaderboard:\n",
      "                   model  score_val          eval_metric  pred_time_val  \\\n",
      "0    WeightedEnsemble_L3  -0.260462  mean_absolute_error    2350.852081   \n",
      "1    WeightedEnsemble_L2  -0.261105  mean_absolute_error    2246.332838   \n",
      "2   LightGBMLarge_BAG_L1  -0.261951  mean_absolute_error     888.315150   \n",
      "3   LightGBMLarge_BAG_L2  -0.264451  mean_absolute_error    2268.687229   \n",
      "4        LightGBM_BAG_L2  -0.264679  mean_absolute_error    2263.143661   \n",
      "5        CatBoost_BAG_L2  -0.264681  mean_absolute_error    2255.159857   \n",
      "6   CatBoost_r177_BAG_L2  -0.265808  mean_absolute_error    2254.410132   \n",
      "7   LightGBM_r131_BAG_L2  -0.265816  mean_absolute_error    2265.896403   \n",
      "8      LightGBMXT_BAG_L2  -0.266684  mean_absolute_error    2315.362953   \n",
      "9        LightGBM_BAG_L1  -0.267526  mean_absolute_error     628.072803   \n",
      "10     LightGBMXT_BAG_L1  -0.271217  mean_absolute_error     721.900634   \n",
      "11       CatBoost_BAG_L1  -0.272542  mean_absolute_error       8.017347   \n",
      "12  CatBoost_r177_BAG_L1  -0.292971  mean_absolute_error       1.935467   \n",
      "13  LightGBM_r131_BAG_L1  -0.614340  mean_absolute_error       2.273271   \n",
      "\n",
      "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   22094.569978                0.042401           2.734588            3   \n",
      "1   15156.946047                0.026902           1.540945            2   \n",
      "2    1829.450926              888.315150        1829.450926            1   \n",
      "3   15658.505102               18.172556         227.671510            2   \n",
      "4   15658.929943               12.628988         228.096351            2   \n",
      "5   21023.143081                4.645183        5592.309490            2   \n",
      "6   16219.673985                3.895459         788.840394            2   \n",
      "7   15549.345941               15.381729         118.512350            2   \n",
      "8   16043.758038               64.848280         612.924447            2   \n",
      "9    1821.937453              628.072803        1821.937453            1   \n",
      "10   1729.876464              721.900634        1729.876464            1   \n",
      "11   9774.140260                8.017347        9774.140260            1   \n",
      "12    256.599699                1.935467         256.599699            1   \n",
      "13     18.828790                2.273271          18.828790            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0        True         14  \n",
      "1        True          7  \n",
      "2        True          4  \n",
      "3        True         11  \n",
      "4        True          9  \n",
      "5        True         10  \n",
      "6        True         12  \n",
      "7        True         13  \n",
      "8        True          8  \n",
      "9        True          2  \n",
      "10       True          1  \n",
      "11       True          3  \n",
      "12       True          5  \n",
      "13       True          6  \n",
      "\n",
      "ðŸ” Importancia de Features:\n",
      "             feature  importance    stddev   p_value  n  p99_high   p99_low\n",
      "0              trend    0.207434  0.020595  0.000012  5  0.249839  0.165030\n",
      "1               tn_x    0.070927  0.012594  0.000114  5  0.096858  0.044996\n",
      "2        descripcion    0.060360  0.011173  0.000135  5  0.083366  0.037354\n",
      "3      slope_trend_3    0.058624  0.006727  0.000020  5  0.072475  0.044772\n",
      "4         rollmean_5    0.046893  0.006238  0.000037  5  0.059737  0.034049\n",
      "..               ...         ...       ...       ... ..       ...       ...\n",
      "95  diff_rollmean_21    0.006147  0.000579  0.000009  5  0.007339  0.004955\n",
      "96       rollmean_13    0.006025  0.001190  0.000174  5  0.008476  0.003574\n",
      "97          sku_size    0.005870  0.001977  0.001335  5  0.009941  0.001800\n",
      "98       rollmean_20    0.005828  0.001448  0.000422  5  0.008809  0.002846\n",
      "99       rollmean_23    0.005358  0.001513  0.000688  5  0.008473  0.002244\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 9) Leaderboard (performance interna)\n",
    "# -------------------------------\n",
    "print(\"\\nðŸ” Leaderboard:\")\n",
    "lb = predictor_top40.leaderboard(silent=True)\n",
    "print(lb)\n",
    "\n",
    "# -------------------------------\n",
    "# 10) Importancia de features\n",
    "# -------------------------------\n",
    "print(\"\\nðŸ” Importancia de Features:\")\n",
    "fi = predictor_top40.feature_importance(train_top40[features_top40 + ['clase']])\n",
    "fi = fi.reset_index().rename(columns={'index': 'feature'})\n",
    "print(fi.head(100))\n",
    "fi.to_csv('importancia_feature_modelo_customer_product_hib_20-07-25_Autogluon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b90fb4-0bd8-43cf-8f9c-e01bb9c9cade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b1f26-ae7e-4ecf-8722-69bc366ebdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ”„ BLOQUE 3 â€” Modelo SERIES DE TIEMPO para resto de clientes\n",
    "# ============================================================\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "# âš™ï¸ 1) Agregar por producto\n",
    "df_resto_prod = (\n",
    "    df_otros.groupby(['product_id', 'fecha'], as_index=False)\n",
    "    .agg({'tn_x': 'sum'})\n",
    ")\n",
    "\n",
    "# ðŸ‘‰ Renombrar para TimeSeriesDataFrame\n",
    "df_resto_prod = df_resto_prod.rename(columns={\n",
    "    'product_id': 'item_id',\n",
    "    'fecha': 'timestamp'\n",
    "})\n",
    "df_resto_prod['timestamp'] = pd.to_datetime(df_resto_prod['timestamp'])\n",
    "df_resto_prod = df_resto_prod.sort_values(['item_id', 'timestamp'])\n",
    "\n",
    "# âš™ï¸ 2) Crear objeto TimeSeriesDataFrame\n",
    "ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_resto_prod,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "print(ts_df.head())\n",
    "\n",
    "# âš™ï¸ 3) Configurar predictor\n",
    "predictor_resto = TimeSeriesPredictor(\n",
    "    target='tn_x',\n",
    "    prediction_length=2,\n",
    "    freq='M',\n",
    "    eval_metric='MAE'\n",
    ")\n",
    "\n",
    "# âš™ï¸ 4) Entrenar\n",
    "predictor_resto.fit(ts_df, num_val_windows=2, time_limit=14400)\n",
    "\n",
    "# âš™ï¸ 5) Predecir\n",
    "forecasts = predictor_resto.predict(ts_df)\n",
    "forecasts_df = forecasts.reset_index().groupby('item_id')['mean'].sum().reset_index()\n",
    "forecasts_df.columns = ['product_id', 'tn']\n",
    "\n",
    "print(forecasts_df.head())\n",
    "\n",
    "# âš™ï¸ 6) Guardar\n",
    "forecasts_df.to_csv('forecast_resto_top125_202002.csv', index=False)\n",
    "print(\"âœ… Forecast resto clientes guardado.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bb357-00d6-4241-b5ee-424ab350fa7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ðŸ—ƒï¸ BLOQUE 4 â€” Merge forecasts y salida final\n",
    "# ================================================\n",
    "\n",
    "df_top40_pred = pd.read_csv('forecast_top125_202002.csv')\n",
    "df_resto_pred = pd.read_csv('forecast_resto_top125_202002.csv')\n",
    "\n",
    "# âš™ï¸ Unir y sumar por producto\n",
    "df_final = (\n",
    "    pd.concat([df_top40_pred, df_resto_pred], axis=0)\n",
    "    .groupby('product_id', as_index=False)\n",
    "    .agg({'tn': 'sum'})\n",
    ")\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "# âš™ï¸ Guardar archivo final\n",
    "df_final.to_csv('forecast_total_top_125_202002.csv', index=False)\n",
    "print(\"âœ… Forecast combinado guardado: forecast_total_202002.csv\")\n",
    "print(f\"Productos Ãºnicos: {df_final['product_id'].nunique()} | TN totales: {df_final['tn'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a5afb-df69-4948-99d4-90b94f8bbbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311409e-077e-4fa2-ab00-f685458658dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ab466-eddc-41d8-9594-f51f9608c6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
